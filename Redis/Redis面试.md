#**介绍一下redis**

Redis是一款基于键值对的NoSQL数据库，数据结构有。

字符串strings、哈希hashes、列表lists、集合sets、有序集合sorted sets等

Redis 的数据是存在内存中的 ，所以读写速度非常快，因此 Redis 被主要应用于缓存。

同时，Redis还可以将内存中的数据以快照或日志的形式保存到硬盘上，保证数据安全。

另外，Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列（但是不推荐，相比其它mq，它因为太依赖网络io）。

Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。

#**为什么需要redis？**

缓存是高并发场景下提高热点数据访问性能的一个有效手段，在开发项目时会经常使用到。

#**redis基础结构?**

底层实现：

String——》 简单动态字符串

list ——》压缩列表、双向链表

Hash ——》压缩列表、哈希表

Set ——》哈希表和整数数组 类似hashset

Sorted Set——》压缩列表、跳表     

其中

##**String字符串**

格式: set key value

string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。

string类型是Redis最基本的数据类型，一个键最大能存储512MB。

简单动态字符串SDS

```java
struct sdshdr {
	int len; //记录buf数组中已使用的字节数量，等于SDS所保存的字符串长度
	int free; //记录buf数组中未使用的字节数量
//在最新版的Redis中，SDS的结构体中已经移除了free属性，转而使用alloc来代替，不过两个属性的含义有所不同，但在SDS中起到的作用基本一致
	char buf[]; //字节数组，用来保存字符串的值 
}
```

**SDS与C字符串区别：**

1，**获取字符串长度时，C字符串需要遍历字符串直到找到‘\0’为止，它的复杂度为O(n),而SDS直接访问len属性就可以直接获取字符串的长度，复杂度为O(1)**。因为传统C字符串符合ASCII编码，这种编码的操作的特点就是：遇零则止 。即，当读一个字符串时，只要遇到’\0’结尾，就认为到达末尾，就忽略’\0’结尾以后的所有字符。因此，如果传统字符串保存图片，视频等二进制文件，操作文件时就被截断了。

而SDS表头的buf被定义为字节数组，因为判断是否到达字符串结尾的依据则是表头的len成员，这意味着它可以存放任何二进制的数据和文本数据，包括’\0’，

2，SDS的api杜绝缓存区溢出，SDS调用SdsCat时，会首先判断 sds的空间是否充足，如果不够要先扩展SDS，再进行字符串拼接。

3，为了减少内存重分配的性能影响，SDS的字符串增长会做内存预分配操作，通过预分配策略，可以有效的减少redis分配内存的次数。

**空间预分配策略用于优化SDS的字符串增长操作:**

- 如果对SDS进行修改后，SDS表头的len成员小于1MB，那么就会分配和len长度相同的未使用空间。free和len成员大小相等。
- 如果对SDS进行修改后，SDS的长度大于等于1MB，那么就会分配1MB的未使用空间。

**惰性删除：**

惰性空间释放用于优化 SDS 的字符串缩短操作： 当 SDS 的 API 需要缩短 SDS 保存的字符串时， 程序并不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。

**编码**

字符串对象的编码可以是int、raw或者embstr。其中int表示整型的值，embstr表示小于等于39字节的字符串值，剩余的均用raw表示，并且int和embstr都是只读的，一旦发生了append操作，即会转换为raw。

##**Hash（哈希）**

1. **介绍** ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，**特别适合用于存储对象**，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。
2. **常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。
3. **应用场景:** 系统中对象数据的存储。

 

##**List（列表）**

1. **介绍** ：**list** 即是 **链表**。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 **LinkedList**，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 **双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。
2. **常用命令:** `rpush,lpop,lpush,rpop,lrange、llen` 等。
3. **应用场景:** 发布与订阅或者说消息队列、慢查询。

##**Set（集合）**

1. **介绍 ：** set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。
2. **常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。
3. **应用场景:** 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

##**zset(sorted set：有序集合)**

1. **介绍：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。
2. **常用命令：** `zadd,zcard,zscore,zrange,zrevrange,zrem` 等。
3. **应用场景：** 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。

#底层实现

##**[redisObject](https://www.cnblogs.com/wind-snow/p/11172832.html)**

Redis 并没有直接使用这些数据结构来实现键值对的数据库，而是在这些数据结构之上又包装了一层 RedisObject（对象）

使用 RedisObject 的优点主要有两个，分别是：

1. 通过不同类型的对象，Redis 可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令。
2. 我们可以针对不同的使用场景，为对象设置不同的实现，从而优化内存或查询速度。

```java
typedef struct redisObject {

    // 类型
    unsigned type:4;

    // 编码
    unsigned encoding:4;

    // 对象最后一次被访问的时间
    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */

    // 引用计数
    int refcount;

    // 指向实际值的指针
    void *ptr;

} robj;
```

##**压缩列表**

压缩列表是Redis为节约内存自己设计的一种顺序型数据结构。类似数组，通过一片连续的内存空间，来存储数据。不过，它跟数组不同的一点是，它允许存储的数据大小不同。

ziplist其实是一个逻辑上的双向链表，可以快速找到头节点和尾节点，然后每个节点(entry)中也包含指向前/后节点的"指针"，但作者为了将内存节省到极致，摒弃了传统的链表设计(前后指针需要16字节的空间，而且会导致内存碎片化严重)，设计出了内存非常紧凑的存储格式。**内存是省下来了**，但操作复杂性也更新的复杂度上来了。

注：redis 3.2以后，**quicklist作为列表键的实现底层实现之一，代替了压缩列表**。

## 快表

quicklist 实际上是 ziplist和普通的双向链表 linkedList结合起来。每个双链表节点中保存一个ziplist，然后每个ziplist中存一批list中的数据(具体ziplist大小可配置)，这样既可以避免大量链表指针带来的内存消耗，也可以避免ziplist更新导致的大量性能损耗，将大的ziplist**化整为零**。

![](https://hunter-image.oss-cn-beijing.aliyuncs.com/redis/quicklist/QuickList.png)

## 字典hash

Redis 中的字典相当于 Java 中的 **HashMap**，内部实现也差不多类似，都是通过 **"数组 + 链表"** 的链地址法来解决部分 **哈希冲突**，

### 渐进式 rehash

大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个 O(n) 级别的操作，作为单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 **渐进式 rehash** 小步搬迁：

![图片](https://mmbiz.qpic.cn/mmbiz_png/ia1kbU3RS1H5tIHy6ebDys4qIicGZ07dLVzL3lGyrSnjpfThSUnBTibic9O1HoWRXwtLq3FfJSwqhu8UDib74VRMyXw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，如上图所示，查询时会同时查询两个 hash 结构，然后在后续的定时任务以及 hash 操作指令中，循序渐进的把旧字典的内容迁移到新字典中。当搬迁完成了，就会使用新的 hash 结构取而代之。

### 扩缩容的条件

正常情况下，当 hash 表中 **元素的个数等于第一维数组的长度时**，就会开始扩容，扩容的新数组是 **原数组大小的 2 倍**。不过如果 Redis 正在做 `bgsave(持久化命令)`，为了减少内存也得过多分离，Redis 尽量不去扩容，但是如果 hash 表非常满了，**达到了第一维数组长度的 5 倍了**，这个时候就会 **强制扩容**。

当 hash 表因为元素逐渐被删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。所用的条件是 **元素个数低于数组长度的 10%**，缩容不会考虑 Redis 是否在做 `bgsave`。

## **跳表**

- 跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

- 跳跃表以空间换时间的方式提升了查找速度

- Redis有序集合在节点元素较大或者元素数量较多时使用跳跃表实现

  是有序集合的底层实现之一。

  [![img](https://camo.githubusercontent.com/db0608e3c815e8ae059eb769b5ad96cd375edb9be9d3f5e9a501f50bea030fc5/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62656261363132652d646335622d346663322d383639642d3062323334303861633930612e706e67)](https://camo.githubusercontent.com/db0608e3c815e8ae059eb769b5ad96cd375edb9be9d3f5e9a501f50bea030fc5/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62656261363132652d646335622d346663322d383639642d3062323334303861633930612e706e67)

  

  在查找时，从上层指针开始查找，找到对应的右闭区间之后再到下一层去查找。下图演示了查找 22 的过程。

  [![img](https://camo.githubusercontent.com/90f439265419d783c6059075bc02be6dd7056356a0e9a88f412790214a70e10d/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30656133376565322d633232342d346337392d623839352d6531333163363830356334302e706e67)](https://camo.githubusercontent.com/90f439265419d783c6059075bc02be6dd7056356a0e9a88f412790214a70e10d/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30656133376565322d633232342d346337392d623839352d6531333163363830356334302e706e67)

  

  与红黑树等平衡树相比，跳跃表具有以下优点：

  - 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；（先确定该元素要占据的层数 K（采用丢硬币的方式，这完全是随机的）

    然后在 Level 1 ... Level K 各个层的链表都插入元素。如果 K 大于链表的层数，则要添加新的层。）
  
  - 更容易实现；
  
  - 支持无锁操作。

#缓存有哪些类型？

缓存的类型分为：本地缓存、分布式缓存和多级缓存。

#本地缓存

本地缓存就是在进程的内存中进行缓存，比如我们的 JVM 堆中，可以用 LRUMap 来实现，也可以使用 Ehcache 这样的工具来实现。

本地缓存是内存访问，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展。

#分布式缓存

分布式缓存可以很好得解决这个问题。

分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存。

#多级缓存

为了平衡这种情况，实际业务中一般采用多级缓存，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。

在目前的一线大厂中，这也是最常用的缓存方案，单考单一的缓存方案往往难以撑住很多高并发的场景。

#redis比本地缓存的好处在哪里？

1. 读写速度，不考虑并发问题，本地缓存自然是最快的。但是如果本地缓存不加锁，那应并发了咋办呢？
2. 场景使用，同一数据，从数据库取出来，放到redis只要一次，而放到本地缓存，则需要n个集群次
3. 本地缓存无法用于重复点击，重复点击会分发请求到多台服务器，而用本地缓存只能防止本机重复点击，redis则可以防止，但是时间间隔也需要在redis的读写差之外。
4. redis内存可能n多扩充，而本地扩大堆内存代价是很大的。
5. 本地缓存需要自己实现过期功能，实现不好可能导致极其严重的后果，而redis经过大量的流量验证，许多漏洞无需考验，安全。
6. 本地缓存无法提供丰富的数据结构，redis可以。
7. redis可以写磁盘，持久化，本地缓存不可以或者说很麻烦要考虑的东西太多。
8. 各位开发同学水平差别大，使用本地缓存极有可能导致严重的线程安全问题，并发考虑严重。
9. 加本地缓存后，代码复杂度急剧上升，后面进来的开发很难一下领会原有开发想法。间接提升维护成本。
10. 其实在map和redis取值这里省的时间，可能在我们写得乱七八糟的代码里，早都不算啥了，所有有时候咱们真的没必要较那几毫秒的真！

#**redis为什么是单线程?**

redis单线程是指redis的网络io和键值对读写是只有一个线程来完成的，这也是redis对外提供键值存储服务的主要流程。但其他的功能是由额外的线程执行的。

redis采用单线程的原因，是因为多线程会有共享资源的并发访问控制问题，为了避免这些问题，redis采用单线程，大大降低redis内部实现的复杂度。

同时，Redis是单线程，主要是是指Redis的网络IO和键值对读写是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程。但Redis的其它功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

#**redis为什么这么快?**

- 纯内存操作，redis的大部分操作在内存上完成，再加上它用了高效的数据结构，例如哈希表和跳表
- 单线程操作，避免了频繁的上下文切换
- 采用了非阻塞 I/O 多路复用机制，redis使用了多路复用机制，使其网络io操作中能并发处理大量客户端请求
  * `IO`多路复用程序会同时监听多个`socket`，当被监听的`socket`准备好执行`accept`、`close`、`read`、`write`等操作时，与这些操作相对应的文件事件就会产生。`IO`多路复用程序会把所有产生事件的`socket`压入一个队列中，然后有序地每次仅一个`socket`的方式传送给文件事件分派器，文件事件分派器接收到`socket`之后会根据`socket`产生的事件类型调用对应的事件处理器进行处理。

#**redis6.0版本为什么又引入了多线程?**

redis的瓶颈不在cpu，而在于内存和网络，内存不够可以加内存或数据结构优化，但redis的网络io的读写占用了部分cpu的时间，如果可以把网络处理改成多线程，性能可以提升。

引入多线程有两个原因

1、充分利用服务器的多核资源

2、多线程分摊redis同步io读写压力

执行命令还是单线程顺序执行，只是网络数据的读写采用了多线程，并且它io线程要么同时读要么同时写。

#**多路复用的高性能io模型**：epoll实现Reactor模式

阻塞模式的话一个操作会阻塞导致其它操作等到

所以用的是非阻塞模式

Redis网络框架调用epoll机制，让内核监听这些套接字。此时，Redis线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis可以同时和多个客户端连接并处理请求，从而提升并发性。

![img](C:\Users\11468\AppData\Local\YNote\data\qq11124F018E6DD55F4F5DD4125E058357\c32a5a2c31a44c0f80fe0965cb0882cb\截图.png)

一旦有请求到达，事件发生，比如acceptevent、readevent、writeevent,事件入队到时间处理队列，然后事件出队，就会交给回调Redis相应的accept和get函数进行处理，这就实现了一个redis线程处理多个io流的效果。

#**redis支持高并发的原因？**

- redis是基于内存的，内存读写很快
- redis采用了单线程的模型，保证了每个操作的原子性
- redis的是单线程的，省去了很多多线程上下文切换的时间
- redis虽然是单线程，但采用了IO多路复用技术，非阻塞IO，即多个网络连接复用一个线程，保证多连接的同时增加系统的吞吐量 使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。
- redis的数据结构，采用hash,读取速度比较快

#Redis的过期/删除策略

我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。

过期策略通常有以下三种：

- 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。
- 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。
- 定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
  (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

Redis中同时使用了惰性过期和定期过期两种过期策略。

#数据淘汰策略

可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。

Redis 具体有 6 种淘汰策略：

| 策略            | 描述                                                 |
| --------------- | ---------------------------------------------------- |
| volatile-lru    | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 |
| volatile-ttl    | 从已设置过期时间的数据集中挑选将要过期的数据淘汰     |
| volatile-random | 从已设置过期时间的数据集中任意选择数据淘汰           |
| allkeys-lru     | 从所有数据集中挑选最近最少使用的数据淘汰             |
| allkeys-random  | 从所有数据集中任意选择数据进行淘汰                   |
| noeviction      | 禁止驱逐数据                                         |

作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。

Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。

# 事务

**Redis事务的概念：**

　　Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。

　　总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。　　

**Redis事务没有隔离级别的概念：**

　　批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到。

**Redis不保证原子性：**

　　Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。

#**缓存与一致性问题**

![img](C:\Users\11468\AppData\Local\YNote\data\qq11124F018E6DD55F4F5DD4125E058357\5fda4fa58f0c4343b30f9dec6109edfe\截图.png)

- 重试数据库更新

将要更新的数据库值暂存到消息队列中，进行重试机制，成功就在队列中去除这个值超过一定次数失败就报错给业务层

- 延迟双删

更新数据库后，先sleep一小段时间，再进行一次缓存删除。之所以要等待一段时间是因为需要等另一个线程b的读数据库，然后把它写入缓存的操作时间。然后线程a再进行删除，这个等待时间要大于操作时间(根据业务和程序操作时间计算)

- 重试缓存删除

在tomcat与redis缓存之间加一层消息队列，把需要删除的缓存值先入队，再去删除缓存值，如果缓存值删除成功，就把值在消息队列中去除；如果删除缓存失败，消息队列进行重试，重试超过一定次数就向业务层发报错。

- 等待缓存删除完成，期间会有不一致数据短暂存在

对于写操作配合分布式锁使用。当写操作进来时针对同一个资源的修改操作，先加分布式锁，这样同一时间只允许一个线程去更新数据库和缓存

**总结**

**优先使用先更新数据库再删除缓存。**

**主要原因两个：**

- **1.先删除缓存值，再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力。**
- **2.如果业务应用中更新数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间不好设置**

https://juejin.cn/post/6844904034252357645

#**如何解决缓存雪崩、击穿、穿透?**

缓存血崩

目前电商首页以及热点数据都会去做缓存 ，一般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有一个问题。

在批量往**Redis**存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效。

如果**Redis**是集群部署，将热点数据均匀分布在不同的**Redis**库中也能避免全部失效的问题，不过在生产环境中操作集群的时候，可以单个服务是对应的单个**Redis**分片，这是为了方便数据的管理，但是也同样有了可能会失效这样的弊端，失效时间随机是个好策略。

缓存击穿

设置热点数据永远不过期。或者加上互斥锁就能搞定了，分布式锁的话要靠lua脚本。

缓存穿透

- 从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值具体取啥问产品，或者看具体的场景，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。

这样可以防止攻击用户反复用同一个id暴力攻击，但是我们要知道正常用户是不会在单秒内发起这么多次请求的，那网关层**Nginx**本渣我也记得有配置项，可以让运维大大对单个IP每秒访问次数超出阈值的IP都拉黑。

- 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。

- **布隆过滤器**快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。

（1）原理：将要添加的元素给 k 个哈希函数然后得到对应于**位数组**上的 k 个位置，将这k个位置设为 1

（2）缺点：没有删除方法，因为实现原理，一旦删除会提高误判率。——解决办法：位数组变成整数数组，每插入一个元素相应的计数器加 1, 这样删除元素时将计数器减掉就可以了。但是还有一个问题，我们必须保证删除的元素一定在布隆过滤器里面，否则会出现计数器环绕问题。但这一点单凭这个过滤器是无法保证。

（3）流程：1、数据加载到布隆过滤器；

​           2、查询先去布隆过滤器

​           3、布隆过滤器说不存在，就直接返回

​           4、存在就走缓存

​           5、缓存不存在就走数据库

（证的。另外计数器回绕也会造成问题。

- 会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等

![img](C:\Users\11468\AppData\Local\YNote\data\qq11124F018E6DD55F4F5DD4125E058357\aac51d21d0bc46f9b436c8a9eea79d55\截图.png)

#**sentinel 哨兵 - 脑裂处理方案**

https://wenfh2020.com/2019/12/27/redis-split-brain/#top

- redis 脑裂主要表现为，Redis的Sentinel组件会监视集群的状态，可能仅因为Sentinel组件所在服务器和主Redis的网络通讯出现了问题(并不是主Redis故障)，导致发现当前的“主Redis”不可用就会把“从Redis”设为“主Redis”；在做这个主备转换前后，原来已链接“老主Redis”的客户仍然在处理，新加入的链接交给了“新主Redis”，这就导致了**“不一致性”** ；
- 同一个 redis 集群，出现多个 master，导致 redis 集群出现数据不一致。
- 解决方案主要通过 sentinel 哨兵的配置和 redis 的配置去解决问题。
-  min-slaves-to-write 主库能进行数据同步的最少从库数量和 min-slaves-max-lag。设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求了。即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。
- 上述方案也是有不足的地方，例如 redis 配置限制可能会受到副本个数的影响，所以具体设置，要看具体的业务场景。主要是怎么通过比较小的代价去解决问题，或者降低出现问题的概率。
- redis 虽然已经发布了 gossip 协议的无中心集群，sentinel 哨兵模式还是比较常用的，我们不建议直接使用 sentinel，可以使用 codis 这样的第三方代理，还是挺方便实用的。

#**redis的高可靠性**

体现在两个方面

1、数据尽量少丢失

这是用AOF和RDB保证的

2、服务尽量不中断

增加副本冗余

#**redis的AOF和RDB**

**AOF日志：宕机了，Redis如何避免数据丢失？**

由于Redis常常用于当作缓存，所以衍生出一个问题：一旦redis服务器宕机，内存中的数据将全部丢失。

如果从数据库中恢复，频繁访问会给数据库很大的压力，而且这些数据从传统数据库会慢查询，响应速度比不上Redis。

AOF日志：“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。可以避免出现记录错误命令的情况。除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。

**三种写回策略**

但是写回虽然避免了对当前命令的阻塞，但是给下一个操作带来了阻塞风险，AOF是主线程执行，如果日志文件写入ipan每次盘写压力大，就会导致写很慢，进而导致后面的操作无法执行，此时宕机。可能丢失。

AOF 配置项 appendfsync 的三个可选值。

- Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
- Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
- No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

![img](C:\Users\11468\AppData\Local\YNote\data\qq11124F018E6DD55F4F5DD4125E058357\78900f74f20a440bbf6c55c4da4e1c64\截图.png)

总结一下就是：想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择 Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。

**日志文件太大？**

实际上，重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令

#**AOF重写的工作原理**

1、Redis执行fork(),现在同时拥有父进程和子进程。

2、子进程开始将新AOF文件的内容写入到临时文件。

3、父进程对于所有新执行的写入命令，一边将他们累积到一个内存缓存中，一边将这些改动追加到现有AOF文件的末尾，这样即使在重写中途发生停机，现有的AOF也还是安全的。

4、当子进程完成重写工作时，它给父进程发送一个信号，父进程接收到信号之后，将内存缓存中所有数据追加到新AOF文件末尾。

5、现在Redis原子地用新文件替换之前的文件，完成文件的瘦身，之后的命令直接追加新文件的末尾。

#**什么时候触发重写机制？**

有两个配置项在控制AOF重写的触发时机：

- \1. auto-aof-rewrite-min-size: 表示运行AOF重写时文件的最小大小，默认为64MB
- \2. auto-aof-rewrite-percentage: 这个值的计算方法是：当前AOF文件大小和上一次重写后AOF文件大小的差值，再除以上一次重写后AOF文件大小。也就是当前AOF文件比上一次重写后AOF文件的增量大小，和上一次重写后AOF文件大小的比值。

AOF文件大小同时超出上面这两个配置项时，会触发AOF重写。

#**重写会阻塞主线程吗？**

总结来说，每次 AOF 重写时，Redis 会fork，子进程先执行一个拷贝父进程的页表（子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据。），用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。

**RDB快照：redis宕机后如何快速恢复？**

RDB快照：内存快照。所谓内存快照，就是指内存中的数据在某一个时刻的状态记录。

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。

- save：在主线程中执行，会导致阻塞；
- bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。

快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销！！！！

Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。

**redis的主从集群、哨兵机制？**

#**主从集群**

首先为什么采用主从集群读写分离模式？如果用加锁、实例协商是否修改的话，开销太大了。而采用读写分离，所有数据的修改只会在主库上修改，不用协调多个实例。主库有了最新的数据后，回同步给从库，这样主库和从库的数据一致的。

主从库的第一次同步

启动多个 Redis 实例的时候，配置从库执行命令

replicaof（Redis 5.0 之前使用 slaveof）ip 端口号

![img](C:\Users\11468\AppData\Local\YNote\data\qq11124F018E6DD55F4F5DD4125E058357\a8c8a82aa68f4bf49b12281ea46e01e5\截图.png)

**第一阶段**：从库给主库发送psync命令，表示要进行数据同步，主库根据这个命令的参数来启动参数。psync命令里面包括了主库的runID和复制进度offset两个参数

- runID，是每个Redis实例启动时都会自动生成的一个随机ID，用来标识这个实例。当从库和主库第一次复制时，因为不知道主库的runID，所以将runID设为“？”
- offset，此时设为-1，表示第一次复制

主库收到psync命令后，会用FULLRESYNC响应时间命令带上两个参数：主库runID和主库目前的复制进度offset，返回给从库。从库收到响应后，会记录这两个参数。

FULLRESYNC响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。

**第二阶段**：主库执行bgsave命令，生成RDB文件，接着将文件发给从库。从库接收到RDB文件后，会清空当前数据库，然后加载RDB文件。这是因为从库在通过replicaof命令开始和主库同步之前，可能保存了其它的数据。为了避免之前数据的影响，从库需要先把当前数据库清空

在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则Redis的服务就被中断了。但是，这些请求中的写操作有可能并没有被来得及记录到刚刚生成的RDB文件中。为了保证主从库的数据一致性，主库会在内存中专门的replication buffer，专门来记录RDB文件生成后的所有写操作。（这块内存专门用来当作传播写操作的内存，被叫做replication buffer）

**第三阶段**：主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体操作是，当主库完成RDB文件发送后，就会把此时replication buffer中的修改操作发给从库，从库再重新执行这些操作。

但是从库太多的话、主库压力也大，忙于fork子进程去生成RDB文件，进行数据同步，当主库给从库备份的时候，所以出现了主从从模式，将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上,让从库的同步来源于从库

![img](C:\Users\11468\AppData\Local\YNote\data\qq11124F018E6DD55F4F5DD4125E058357\91e17d040da0496e97f31b8d7370e902\截图.png)

一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播

**增量复制**

![img](C:\Users\11468\AppData\Local\YNote\data\qq11124F018E6DD55F4F5DD4125E058357\6b81b0fd7e9d447eaee6839bd64a5c62\截图.png)

因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。因此，我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值

#**哨兵机制**

主库挂了，哨兵负责保证redis服务不间断

哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。

监控：

使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。

为了防止网络拥塞等导致的误判，多个哨兵实例对主库判断

单个哨兵判断下线是“主观下线”，多个哨兵的判断下线是“客观下线”，即少数服从多数

如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。

选主：

先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库。

（1）筛选：检查从库的当前在线状态，还要判断它之前的网络连接状态，配置项down-after-milliseconds是我们认定主从库断连的最大连接时间。如果在这个时间内没有连上，我们认为断连。如果断连次数超过10次，我们就认为这个不适合当主库。

（2）打分：依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。

- 从库优先级可以在slave-priority 配置项手动配置，按照实例的内存设置等级；
- 从库复制进度主从库同步时有个命令传播的过程，主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。此时，我们想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。如果在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就最高，可以作为新主库；
- 在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。

#**为什么用redis做id关系？**

其实这个图片ID和存储对象ID对应关系的存储，就是用在分布式存储系统中的一个小的元数据服务，访问模式也比较简单，key-value的PUT、GET就行，但是要求请求响应快。Redis很轻量级，而且速度也快，所以用的Redis。MySQL用在这个场景中显得有些太重了，这个场景里面没有关系模型，也没有事务需求和复杂查询，上MySQL不太需要。图片数量再增加时，MySQL的表就太大了，插入效率会降低。

#**Redis如何解决多个子系统并发竞争 Key 问题**

这个问题大致就是，同时有多个子系统去 Set 一个 Key。这个时候要注意什么呢?大家基本都是推荐用 Redis 事务机制。

但是我并不推荐使用 Redis 的事务机制。因为我们的生产环境，基本都是 Redis 集群环境，做了数据分片操作。你一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。因此，Redis 的事务机制，十分鸡肋。

##**如果对这个 Key 操作，不要求顺序**

这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。

##**如果对这个 Key 操作，要求顺序**

假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。

期望按照 key1 的 value 值按照 valueA > valueB > valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。