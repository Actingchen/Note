#项目笔记

## 分页

需求：
第一页和尾页

每点击一个已有数字x页码，当前页它会亮，在中间时显示的是左三个右边也三个
假设有12页
当x=1时
1*  2 3 4（没有上一页和第一页的跳转按钮）
当x=2时
1 2* 3 4 5
当x=3时
1 2 3* 4 5 6
当x=4时
1 2 3 4* 5 6 7
当x=7
4 5 6 7* 8 9 10
当x=12
9 10 11 12*(没有下一页和最后一页的跳转按钮）

已知一页有5条话题 size=5

假设一共有60条话题数据
数据表的行数据与页码的匹配id——>pages
id_start , step
          0，5            1 返回第一页
          5，5            2 返回给第二页
         10，5           3 返回给第三页
比如12/5=2，但是我们想它在第三页

所以说
if id%5!=0       id/5+1
else i/5


前端要求返回第i页的数据
则后端sql  ——>  limit (i-1)*5,5

1 2* 3 4 5
1 2 3* 4 5 6

private Integer page;
private List<Integer> pages = new ArrayList<>();
根据当前页码数得到页码数组

```java
for(int i=1;i<=3;i++){
	if(page-i>0){
		pages.add(0,page-i);//当前页码左边展示0~3个
	}
	if(page+i<=totalCount){
		pages.add(page+1);//当前页码右边展示0~3个
	}
}
```



**名词解释：**
InnoDB聚集索引的叶子节点存储行记录，因此， InnoDB必须要有，且只有一个聚集索引：

（1）如果表定义了PK，则PK就是聚集索引；

（2）如果表没有定义PK，则第一个not NULL unique列是聚集索引；

（3）否则，InnoDB会创建一个隐藏的row-id作为聚集索引；

画外音：所以PK查询非常快，直接定位行记录。

InnoDB普通索引的叶子节点存储主键值。

画外音：注意，不是存储行记录头指针，MyISAM的索引叶子节点存储记录指针。

**mysql的limit限制和优化**

限制：
当行数数据量很大的表，进行分页时性能很差
limit10000,20的意思扫描满足条件的10020行，扔掉前面的10000行，返回最后的20行，问题就在这里。
   比如LIMIT 451350 , 30 扫描了45万多行，怪不得慢的都堵死了。

select 


优化：
通过主键索引优化
SELECT * FROM cps_user_order_detail d WHERE d.id > #{maxId} AND d.order_time>'2020-8-5 00:00:00' ORDER BY d.order_time desc LIMIT 6;


如上代码所示，同样也是分页，但是有个maxId的限制条件，这个是什么意思呢，maxId就是上一页中的最大主键Id。
所以采用此方式的前提：
1）主键必须自增不能是UUID并且前端除了传基本分页参数pageNo,pageSize外，还必须把每次上一页的最大Id带过来，
2）该方式不支持随机跳页，也就是说只能上下翻页。如下图所示是某知名电商中的实际页面。

不能说到MySQL优化就是建索引，调整SQL（实际上在真实开发中这两种优化方案的成效微乎其微）。
毕竟MySQL优化那么牛X的话，就不会有那么多中间件产生了。
当然，可能有人会有疑问，说可以分库分表，然后基于用户ID进行hash选择对应的库表
（这样是为了保证统一用户的订单全部入到一张表里）。这么想没问题的，事实上这是电商中的第一道方案。

**什么是分库分表？**

当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库，优化索引，做很多操作时性能还是下降严重。
这时候可以使用分库分表
将数据分散在不同的数据库中，使得单一数据库的数据量变小来缓解单一数据库的性能问题，从而达到提升数据库性能的目的。
情况分为：
垂直分表（将一个表按照字段分为多表，每个表里面都存储其中一部分字段，按热门字段和冷门字段分表）、
垂直分库（不同服务器同库相同代码）、
水平分库（把同一个表的数据按一定规则拆到不同的数据库中，每个库可以放在不同的服务器上。）、
水平分表（在同一个数据库内，把同一个表的数据按一定的规则拆到多个表中。（对数据行拆分，不影响表结构）

一般来说，在系统设计阶段就应该根据业务耦合松紧来确定垂直分库，垂直分表方案，
在数据量及访问压力不是特别大的情况下，首先考虑缓存，读写分离，索引技术等方案，若数据量极大，且持续增长，
再考虑水平分库水平分表方案。

## 标签

![](..\images\tags.jpg)

## 评论回复

建表comment

id （bigint）

parent_id （bigint）父类id

type （int ）父类类型 当1的时候是一级评论 当2的时候是二级回复

commentator （long）评论实体创建者id

gmt_create (bigint)创建的时间戳

gmt_modified (bigint)修改的时间戳

like_count (bigint)点赞

content (varchar)评论文本

coumment_count (int)评论数



根据路径上的id获取帖子实体

点击回复，js跳转到控制层“/comment”，然后局部刷新二级评论









##通知

初步是使用拦截器来通知的

![](..\images\notification.png)

##点赞

**异步请求**

前端点击 赞 将参数携带跳转给js

js将参数json化post请求给likeControlter ，该控制层接收参数，处理后，用map封装成String，String转成json发给前端

js将其json格式解析，指定取出，然后前端的某标签的的text刷新

**redis存储**

```java
//Util
//某个实体收到的赞，如帖子，评论
//库：实体库：实体类型：实体id——>Set用户id
//点赞库：实体库：帖子点赞、评论点赞、回复点赞：实体id——>用户1 id、用户2 id、用户3 id ...
//like:entity:entityType:entityId -> set(userId) 对应set，存入userId
public static String getEntityLikeKey(int entityType, int entityId) {
    return PREFIX_ENTITY_LIKE + entityType + SPLIT + entityId;
}

//某个用户收到的总赞数
//like:user:userId ->int
public static String getUserLikeKey(int userId) {
    return PREFIX_USER_LIKE + SPLIT + userId;
}
```

```java
//Service
//某个实体收到的赞，如帖子，评论

//       点赞者id     实体类型          实体id           实体的创建者id
public void like(Long userId, int entityType, int entityId,int entityUserId){
redisTemplate.execute(new SessionCallback() {
            @Override
            public Object execute(RedisOperations operations) throws DataAccessException {
                String entityLikeKey= RedisKeyUtil.getEntityLikeKey(entityType,entityId);//实体点赞
                String userLikeKey=RedisKeyUtil.getUserLikeKey(entityUserId);//记录每用户被别人赞的总数

                boolean isMember=operations.opsForSet().isMember(entityLikeKey,userId);
                operations.multi();
                if(isMember){
                    operations.opsForSet().remove(entityLikeKey,userId);//实体点赞--
                    operations.opsForValue().decrement(userLikeKey);//点赞--
                }else{
                    operations.opsForSet().add(entityLikeKey,userId);//实体点赞++
                    operations.opsForValue().increment(userLikeKey);//点赞++
                }

                return operations.exec();
            }
        });
    }
```

Set保证了一个用户只能点一次赞

取消赞entityType：entityId下remove 某用户id

点赞entityType：entityId下add 某用户id



## kafka消息队列通知

### 了解BockingQueue

-解决线程通信的问题

-阻塞方法：put、take

好处：

满足一个生产者消费者模式

- 生产者：产生数据的线程
- 消费者：使用数据的线程

当put满队列的时候，put的线程就会被阻塞，阻塞的时候什么都不做，不会占用系统资源

take当发现空队列，同理。有了阻塞队列那么就避免了浪费占用系统资源。

实现类

ArrayBlockingQueue

LinkBlockingQueue

PriorityBlockingQueue、SynchronousQueue、DelayQueue等

### Kafka入门

简介：

* Kafka早先只是一个消息队列，现在是一个分布式的流媒体平台

* 应用：消息系统、日志收集、用户行为追踪、流式处理。

特点：

* 高吞吐量、消息持久化（存在硬盘里采用顺序读写，甚至高于内存读写）、高可靠性（分布式集群部署）、高可扩展性

术语：

- Broker（Kafka 服务器）、Zookeeper（用Zookeeper来管理集群，Kafka里面也有内置的Zookeeper）
- Topic（**点对点：一个数据只能被一个消费者消费**）、Partition（**发布订阅模式，数据可以被多个消费者同时或顺序读取**）、Offset（分区内的索引）
- Leader Replica（主副本，能力强，能处理你的请求，当挂掉的时候主副本选举出一个做主服务）、Follow Replica（随从副本，只存不响应）



d:

> 进入d盘

cd sorftware\kafka_2.12-2.2.0

> 进入kafka目录下

如果是在硬盘是顺序读写，其实是很快的，随机读写就比内存慢很多。

> zookeeper服务开启

bin\windows\zookeeper-server-start.bat config\zookeeper.properties

>kafka-server服务开启

bin\windows\kafka-server-start.bat config\server.properties

> windows系统下
>
> 先创建一个主题

cd bin\windows

kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test

> 查看主题

kafka-topics.bat --list --bootstrap-server localhost:9092

> 生产者

kafka-console-producer.bat --broker-list localhost:9092 --topic test

> 消费者

kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test  --from-beginning



###Spring整合kafka

* 引入依赖
  * spring-kafka

* 配置kafka
  * 配置

* 访问kafka
  * 生产者：
  * kafkaTemplate.send(topic,data);
  * 消费者：
  * @KafkaListener(topic={"test"})
  * public void handleMessage(ConsumerRecord record){ }



```java
<!--Kafka-->
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```











## 搜索

初步