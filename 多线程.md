目录
=================

   * [前序](#前序)
   * [进程](#进程)
   * [线程](#线程)
   * [上下文切换](#上下文切换)
   * [线程的6种状态](#线程的6种状态)
   * [使用多线程](#使用多线程)
      * [继承Thread](#继承thread)
      * [实现Runnable接口](#实现runnable接口)
      * [Callable接口](#callable接口)
   * [死锁](#死锁)
      * [什么是死锁？](#什么是死锁)
      * [如何避免死锁？](#如何避免死锁)
   * [ThreadLocal](#threadlocal)
   * [volatile](#volatile)
      * [jmm](#jmm)
      * [<strong>保证内存可见性</strong>](#保证内存可见性)
      * [<strong>禁止指令重排</strong>](#禁止指令重排)
      * [不保证原子性](#不保证原子性)
      * [适用场景](#适用场景)
      * [dcl](#dcl)
   * [同步性](#同步性)
   * [Synchronized](#synchronized)
      * [<strong>为什么是重量级锁呢？</strong>](#为什么是重量级锁呢)
      * [<strong>优化</strong>](#优化)
      * [<strong>synchronized 关键字最主要的三种使用方式：</strong>](#synchronized-关键字最主要的三种使用方式)
      * [底层实现](#底层实现)
   * [Lock](#lock)
      * [Lock与synchronize的区别](#lock与synchronize的区别)
      * [synchronized 和 ReentrantLock 的区别](#synchronized-和-reentrantlock-的区别)
   * [线程池](#线程池)
      * [线程池好处](#线程池好处)
      * [<strong>执行 execute()方法和 submit()方法的区别是什么呢？</strong>](#执行-execute方法和-submit方法的区别是什么呢)
      * [<strong>如何创建线程池</strong>](#如何创建线程池)
      * [线程池状态](#线程池状态)
      * [重要属性](#重要属性)
         * [1、线程状态和工作线程数量](#1线程状态和工作线程数量)
         * [2、核心线程数和最大线程数](#2核心线程数和最大线程数)
         * [3、创建线程的工厂](#3创建线程的工厂)
         * [4、缓存任务的阻塞队列](#4缓存任务的阻塞队列)
         * [5、非核心线程存活时间](#5非核心线程存活时间)
         * [6、拒绝策略](#6拒绝策略)
      * [工作流程](#工作流程)
         * [1、提交任务](#1提交任务)
         * [2、创建工作线程](#2创建工作线程)
         * [3、启动工作线程](#3启动工作线程)
         * [4、获取任务并执行](#4获取任务并执行)
      * [ThreadPoolExecutor构造函数重要参数分析](#threadpoolexecutor构造函数重要参数分析)
      * [ThreadPoolExecutor 拒绝策略](#threadpoolexecutor-拒绝策略)
      * [线程池原理分析](#线程池原理分析)
   * [CAS](#cas)
   * [ABA](#aba)
   * [Atomic原子类](#atomic原子类)
      * [介绍](#介绍)
      * [JUC 包中的原子类是哪 4 类?](#juc-包中的原子类是哪-4-类)
      * [讲讲 AtomicInteger 的使用](#讲讲-atomicinteger-的使用)
      * [能不能给我简单介绍一下 AtomicInteger 类的原理](#能不能给我简单介绍一下-atomicinteger-类的原理)
   * [AQS](#aqs)
      * [介绍](#介绍-1)
      * [AQS 原理分析](#aqs-原理分析)
         * [原理概览](#原理概览)
         * [AQS 对资源的共享方式](#aqs-对资源的共享方式)
         * [AQS 底层使用了模板方法模式](#aqs-底层使用了模板方法模式)
         * [AQS 组件总结](#aqs-组件总结)
      * [用过 CountDownLatch 么？什么场景下用的？](#用过-countdownlatch-么什么场景下用的)
   * [并发容器](#并发容器)
   * [拾遗补缺](#拾遗补缺)
      * [sleep() 方法和 wait() 方法区别和共同点?](#sleep-方法和-wait-方法区别和共同点)
      * [为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？](#为什么我们调用-start-方法时会执行-run-方法为什么我们不能直接调用-run-方法)
      * [构造方法可以使用 synchronized 关键字修饰么？](#构造方法可以使用-synchronized-关键字修饰么)
      * [synchronized和volatile区别](#synchronized和volatile区别)
      * [Synchoronized和cas的引用场景](#synchoronized和cas的引用场景)



# 前序

##cpu

cpu的执行效率远远高于它的读写效率，为了合理应用，它增加了缓存

1.CPU 增加了缓存，以均衡与内存的速度差异；

2.操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；

3.编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。

# 进程

进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

# 线程

线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

#并行和并发

- **并发：** 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)；
- **并行：** 单位时间内，多个任务同时执行。

# 上下文切换

当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。

# 线程的6种状态

操作系统中线程的状态：新建，就绪，运行，等待，结束。

Thread类的State类定义了java中线程的6中状态：

| 状态           | 说明                                      |
| ------------ | --------------------------------------- |
| new          | 初始状态，线程被创建，但还没有执行start方法                |
| runnable     | 运行状态，线程把操作系统中的就绪和运行两种状态笼统地称作运行中         |
| blocked      | 阻塞状态，表示线程阻塞于锁                           |
| waiting      | 等待状态，表示线程进入等待状态，当前线程需要等待其它线程做出一些通知或中断   |
| time_waiting | 超时等待状态，该线程不同于waiting，它是可以在指定的时间自行返回运行状态 |
| terminated   | 终止状态，表示线程已经执行完毕（比如执行完Runnable 的run方法后）  |

# 使用多线程

## 继承Thread

步骤：

1. 创建一个类，这个类需要**继承Thread**
2. **重写Thread类的run方法**（业务代码）
3. 实例化创建好的线程类
4. 调用实例化对象的start方法启动线程

## 实现Runnable接口

步骤：

1. 创建一个类，这个类需要**实现Runnable接口**
2. **重写Runnable接口的run方法**
3. 实例化创建的这个类
4. 实例化一个Thread对象，并把第3步创建的对象通过Thread的构造方法进行传递 
5. 调用Thread对象的start方法

## Callable接口

步骤：

   1.创建一个类，**实现Callable接口**并指定一个返回类型

   2.**重写Callable接口的call方法**

   3.实例化创建这个类

   4.**把这个类通过FutureTask的构造方法进行传递** 

   5.**FutureTask通过Thread的构造方法进行传递** 

   6.调用Thread对象的start方法

# 死锁

## 什么是死锁？

**一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。**

比如，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。

产生死锁必须具备以下四个条件：

1. **互斥条件**：该资源任意一个时刻只由一个线程占用。
2. **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. **不剥夺条件**:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. **循环等待条件**:若干进程之间形成一种头尾相接的循环等待资源关系。

## 如何避免死锁？

避免死锁，只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下：

1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）

2. **破坏请求与保持条件** ：==一次性申请所有的资源==。——>可以增加一个账本管理员，然后只允许账本管理员从文件架上拿账本，也就是说柜员不能直接在文件架上拿账本，必须通过账本管理员才能拿到想要的账本。用这个管理员来保证他们都能够成功申请到所有资源。

3. **破坏不剥夺条件** ：==占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。==

   java.util.concurrent 这个包下面提供的 Lock 是可以轻松解决这个问题的

4. **破坏循环等待条件** ：==靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。==——>最常见的就是B转A的同时，A转账给B，那么先锁B再锁A，但是，另一个线程是先锁A再锁B，然而，如果两个线程同时执行，那么就是出现死锁的情况，线程T1锁了A请求锁B，此时线程T2锁了B请求锁A，都在等着对方释放锁，然而自己都不会释放锁，故死锁。
   最简单的办法，就是无论哪个线程执行的时候，都按照顺序加锁，即按照A和B的id大小来加锁，这样，无论哪个线程执行的时候，都会先加锁A，再加锁B，A被加锁，则等待释放。这样就不会被死锁了。

# ThreadLocal

**含义**

* ThreadLocal的静态内部类ThreadLocalMap为每个Thread都维护了一个数组table，每个线程都对应一个ThreadLocalMap, 而threadlocal负责访问和维护ThreadLocalMap，即“ThreadLocal相当于维护了一个map，key就是当前线程threadlocal的实例，value就是需要存储的对象。” 

- threadlocal是一个线程内部的存储类，可以在指定线程内存储数据，数据存储以后，只有指定线程可以得到存储数据。

**使用场景**

正因为ThreadLocal的线程隔离特性，使他的应用场景相对来说更为特殊一些。在android中Looper、ActivityThread以及AMS中都用到了ThreadLocal。当某些数据是以线程为作用域并且不同线程具有不同的数据副本的时候，就可以考虑采用ThreadLocal。ThreadLocal能存储当前数据库连接，传值，session管理。比如多线程并发下，数据库连接池对不同线程出现优点事务正常有些事务不正常，通过Thread Local保证线程隔离，只回滚不正常导致失败的事务的该线程的数据库连接condition。

**内存泄漏**

`ThreadLocal` set时是Entry(key, value)set进ThreadLocalMap，而Entry是extends WeakReference<ThreadLocal<?>>的，所以当ThreadLocal=null时，GC会把ThreadLocal回收，但是Thread不死，ThreadLocalMap就会一直存在 ，GC把ThreadLocal回收后，ThreadLocalMap还存在一条无用的信息(key没了，value还在)，这样就造成了内存泄漏，所以在ThreadLocal使用完成后，请调用remove方法

`ThreadLocal`.get()的时候是强引用所以不会发生内存泄漏。

# volatile

## jmm

多核cpu的时代，当前的 Java 内存模型下，线程可以把变量保存**本地内存**（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成读的**数据的不一致**。

**`volatile`**，这就指示 JVM，这个变量对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。

用一句话概括volatile,它能够使变量在值发生改变时能尽快地让其他线程知道.

![img](https://pic3.zhimg.com/80/v2-a1a75c9f7264cf78d0927663371ca9d2_720w.jpg)

> 

## **保证内存可见性**

**基本概念**

可见性是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的。也就是一个线程修改的结果，另一个线程马上就能看到。

**实现原理**

当对非volatile变量进行读写的时候，每个线程先从主内存拷贝变量到CPU缓存中，如果计算机有多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝到不同的CPU cache中。

volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，保证了每次读写变量都从主内存中读，跳过CPU cache这一步。当一个线程修改了这个变量的值，新值对于其他线程是立即得知的。HappenBefore发生的时候，StoreLoad内存屏障会保证读取数据前，写操作已完成，其它线程对此共享变量的高速缓存副本同时失效。**但是不要过多使用，会引发总线风暴。**

总结：volatile 通过内存屏障和缓存一致性协议MESI实现了变量在多核心之间的一致性。

> **总线嗅探技术**，这个写会内存的操作会使得其他处理器里缓存的该内存地址的数据无效

> **MESI缓存一致性协议**，为了保证不同缓存的一致性,一旦某个线程执行了修改(Modify)操作，会立刻使其他层级的缓存失效(invaild)，然后立刻从主存中读取最新值~协议就是这样规定的

>**volatile变量规则**：对一个volatile变量的写，happens- before 于任意后续对这个volatile变量的读

>**volatile的内存原理本质**：有volatile变量修饰共享变量在编译器编译后，后多出一个“lock” 来（lock前缀指令相当于一个内存屏障，会强制将对缓存的修改操作写入主内存），
>
>该字符在多核处理器下回引发两个事件：
>
>1.将当前处理器缓存行的数据写回系统内存；
>
>2.这个写会内存的操作会使得其他处理器里缓存的该内存地址的数据无效。
>
>**对volatile的写、读操作的描述**
>
>1.当写一个volatile变量时，JMM（java共享内存模型）会把该线程对应的本地内存中的共享变量值刷新到主内存；
>
>2.当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来从主内存中读取共享变量。



## **禁止指令重排**

**基本概念**

计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令重排，尽可能去提高并行度。多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测。

**禁止指令重排的原理**

Volatile实现禁止指令重排优化，从而避免了多线程环境下程序出现乱序执行的现象

首先了解一个概念，**内存屏障**（Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个：

- 保证特定操作的顺序
- 保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）
  由于编译器和处理器都能执行指令重排的优化，如果在指令键插入一条Memory Barrier则会告诉编译器和CPU,不管什么指令都不能和这条Memory Barrier指令重排序，也就是说，通过插入内存屏障前后的指令执行重排序优化。内存屏障另外一个作用是刷新出各种CPU的缓存数，因此任何cpu上的线程都能读取到这些数据的最新版本
  [![img](https://img2020.cnblogs.com/blog/1164910/202008/1164910-20200816171308095-1818218127.png)](https://img2020.cnblogs.com/blog/1164910/202008/1164910-20200816171308095-1818218127.png)
  也就是在Volatile的写和读的时候，加入屏障，防止出现指令重排

volatile屏蔽掉了JVM中必要的代码优化，所以在效率上比较低，因此只有在必要时才使用此关键字。

## 不保证原子性

**原子性**：是要么全部成功，要么全部失败。

简单的说，修改volatile变量分为四步：

1）读取volatile变量到local

2）修改变量值

3）local值写回

4）插入内存屏障，即lock指令，会使其他CPU的缓存无效化，这个使其他线程重新刷新缓存，读取volatile变量，让其它线程立即可见。

但是，内存屏障只会让其他线程每次读取强制从主存读取。你还没修改之前别人已经读了，自然没办法刷新。

这也就是为什么，volatile只用来保证变量可见性，但不保证原子性。

eg：线程1线程2对i=1进行i++，我们期望i=2，假如线程1、2同时读到是1，并且都执行i++准备写回主存，此时如果，线程1写回成功，线程2此时虽然可见，但是线程2的读和计算在线程1写回之前已经读过了，所以线程2写回，相当于是覆盖，相当于是这个i++是无效的。所以i<2.

## 适用场景

- 对变量的`写`入操作`不依赖变量的当前值`，或能确保`只有单个线程更新`变量的值；
- 该变量没有包含在其他变量的不变式中
- 在访问变量时`不需要加锁`。

## dcl

**双重校验锁实现对象单例（线程安全）**

```
public class Singleton {

    private volatile static Singleton uniqueInstance;

    private Singleton() {
    }

    public  static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
            //不为空就直接返回引用了
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

另外，需要注意 `uniqueInstance` 采用 `volatile` 关键字修饰也是很有必要。

`uniqueInstance = new Singleton();` 这段代码其实是分为三步执行：

1. 为 `uniqueInstance` 分配内存空间
2. 初始化 `uniqueInstance`
3. 将 `uniqueInstance` 指向分配的内存地址

（不加voliate时）但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 `getUniqueInstance`() 后发现 `uniqueInstance` 不为空，因此返回 `uniqueInstance`，但此时 `uniqueInstance` 还未被初始化。

**解决办法**

用volatile关键字修饰instance变量，使得uniqueInstance在读、写操作前后都会插入内存屏障，避免重排序，保证在多线程环境下也能正常运行。

# 同步性

可以使用Synchronized和锁对象

# Synchronized

**`synchronized` 关键字解决的是多个线程之间访问资源的同步性，`synchronized`关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。**

另外，在 Java 早期版本中，`synchronized` 属于 **重量级锁**，效率低下。

## **为什么是重量级锁呢？**

因为监视器锁（monitor）是依赖于底层的操作系统的 `Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。

## **优化**

庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对 synchronized 较大优化，即在JVM层级实现锁，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6 对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

## **synchronized 关键字最主要的三种使用方式：**

**1.修饰实例方法:** `synchronized` 关键字加到实例方法上是给对象实例上锁。

**2.修饰静态方法:**`synchronized` 关键字加到 `static` 静态方法和 `synchronized(class)` 代码块上都是是给 Class 类上锁。

**3.修饰代码块** ：指定加锁对象，对给定对象/类加锁。`synchronized(this|object)` 表示进入同步代码库前要获得**给定对象的锁**。`synchronized(类.class)` 表示进入同步代码前要获得 **当前 class 的锁**

注意：

- 尽量不要使用 `synchronized(String a)` 因为 JVM 中，字符串常量池具有缓存功能！String不能用作同步块的参数是因为String为不可变对象，任何String对象的改变都将产生一个新的String对象，这也将导致前面加的锁不会被释放。

- Integer、Boolean、Double、Long不能作为同步块参数的原因是他们是基本包装类型，包装类型有特殊的逻辑，用一句话说就是Java的自动封箱和解箱操作会导致这些对象在经过运算后不再是原来的对象。

  用复杂的话说就是：当把基本变量赋值给包装类型的变量（其实编译过后的操作就是调用包装类型的静态方法valueOf）或者调用静态valueOf方法时：

  - Boolean返回的是缓存的对象。
  - 整型（Byte,Short,Integer,Long）会检查该数字是否在1个字节可表示的有符号整数范围内（-128~127），是则返回缓存对象，否则返回新对象。
  - Character会缓存整型值为0~127的字符，同样会检查字符是否落在缓存范围中，是则返回，否则返回新对象。
  - Double和Float的valueOf方法始终返回新对象。

## 锁升级

**Monitor**

Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。

通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点：

![](C:\Users\11468\Desktop\Study\Note\images\对象头.png)

**无锁**

无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。

无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。

**偏向锁**

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。

在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。

当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。

偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。

**轻量级锁**

是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。

在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。

拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。

如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。

如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。

若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。

**重量级锁**

烈的竞争进入锁升级状态，变成重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。

**为什么非公平？**

此时，重量级锁，对象头的mark word里面的标识 会指向对象监视器moniter address  监视器里面有个owner指向线程（表示被哪个线程占据）

当其它线程来访问时，他会先试图直接修改owner，修改失败就会放进锁池即队列里面等待，本质上是非公平锁。owner释放锁owner=null的时候回去锁池唤醒等待线程，等待线程唤醒后就去试图修改owner。

##Synchronized的缺陷

1. 等待中的线程不能被中断
2. 获取锁有没有成功无法获知
3. 当多个线程只是进行读操作时，可以实现线程不冲突

# Lock

Java中另外一个实现锁的接口

```
由于lock不能实现自动释放锁，所以需要手动释放，容易造成死锁，特别注意复制代码
```

##Lock主要方法

1. lock()--获取锁，如果其他线程已经获取锁则等待，不可中断
2. unlock()--解锁
3. trylock()--获取锁，成功获取返回true，否则不等待直接返回false
4. trylock(long time, TimeUnit unit)--在3的基础上，如果未获取锁则等待time时间，在此期间如果获取到锁则返回true，否则false
5. lockInteruptly()--获取锁，如果其他线程已经获取锁则等待，可以中断

## Lock与synchronize的区别

1. lock是接口，synchronized是Java关键字
2. synchronized可以自动释放锁（执行完毕或异常），lock需要手动释放
3. synchronized等待中的线程不可中断，lock可以
4. lock可以提高多线程读的效率
5. lock可以得到获取锁的结构

## synchronized 和 ReentrantLock 的区别

两者都是可重入锁。

**“可重入锁”** 指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。

`synchronized` 是依赖于 JVM 实现的，`ReentrantLock` 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成）

##**ReentrantLock--可重入锁**

相比`synchronized`，`ReentrantLock`增加了一些高级功能。主要来说主要有三点：

- **等待可中断** : `ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。(如果要求被中断线程不能参与锁的竞争操作，则此时应该使用lockInterruptibly方法，一旦检测到中断请求，立即返回不再参与锁的竞争并且取消锁获取操作)
- **可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock`默认情况是非公平的，可以通过 `ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。
- **可实现选择性通知（锁可以绑定多个条件）**: `synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。

`Condition`是 JDK1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个`Lock`对象中可以创建多个`Condition`实例（即对象监视器），**线程对象可以注册在指定的`Condition`中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用`notify()/notifyAll()`方法进行通知时，被通知的线程是由 JVM 选择的，用`ReentrantLock`类结合`Condition`实例可以实现“选择性通知”** ，这个功能非常重要，而且是 Condition 接口默认提供的。而`synchronized`关键字就相当于整个 Lock 对象中只有一个`Condition`实例，所有的线程都注册在它一个身上。如果执行`notifyAll()`方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而`Condition`实例的`signalAll()`方法 只会唤醒注册在该`Condition`实例中的所有等待线程。

**如果你想使用上述功能，那么选择 ReentrantLock 是一个不错的选择。性能已不是选择标准**

##**ReadWriteLock--读写锁**

特点：独占锁（写锁）一次只能被一个线程占有，共享锁（读锁）多个线程可以同时占有。读锁和读锁 可以共存、读锁和写锁 互斥、写锁和写锁 互斥。

| 标题                          | 链接                                       |
| ----------------------------- | ------------------------------------------ |
| 读写锁ReadWriteLock的实现原理 | https://juejin.im/post/6844903988169555975 |

# 线程池

## 线程池好处

借用《Java 并发编程的艺术》提到的**使用线程池的好处**：

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

## **执行 execute()方法和 submit()方法的区别是什么呢？**

1. **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**
2. **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

##submit里面出现了异常会发生什么？

我们以**`AbstractExecutorService`**接口中的一个 `submit` 方法为例子来看看源代码：

```
    public Future<?> submit(Runnable task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<Void> ftask = newTaskFor(task, null);
        execute(ftask);
        return ftask;
    }
```

上面方法调用的 `newTaskFor` 方法返回了一个 `FutureTask` 对象。

```
    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {
        return new FutureTask<T>(runnable, value);
    }
```

我们再来看看`execute()`方法：

```
    public void execute(Runnable command) {
      ...
    }
```

   1.创建一个类，**实现Callable接口**并指定一个返回类型

   2.**重写Callable接口的call方法**

   3.实例化创建这个类

   4.**把这个类通过FutureTask的构造方法进行传递** 

   5.**FutureTask通过Thread的构造方法进行传递** 

   6.调用Thread对象的start方法

submit(Runnable task) 里面传进去的是futureTask，调用的是里面的call方法，当里面出现异常，会被catch

```
public class FutureTask<V> implements RunnableFuture<V> {
    private volatile int state;
    private static final int NEW          = 0;
    private static final int COMPLETING   = 1;
    private static final int NORMAL       = 2;
    private static final int EXCEPTIONAL  = 3;
    private static final int CANCELLED    = 4;
    private static final int INTERRUPTING = 5;
    private static final int INTERRUPTED  = 6;

    private Callable<V> callable;

    private Object outcome; // non-volatile, protected by state reads/writes
  
    private volatile Thread runner;
  
    private volatile WaitNode waiters;
```

```java
try {
            Callable<V> c = callable;
            if (c != null && state == NEW) {
                V result;
                boolean ran;
                try {
                    result = c.call();
                    ran = true;
                } catch (Throwable ex) {
                    result = null;
                    ran = false;
                    setException(ex);
                }
                if (ran)
                    set(result);
            }
        } finally {
            // runner must be non-null until state is settled to
            // prevent concurrent calls to run()
            runner = null;
            // state must be re-read after nulling runner to prevent
            // leaked interrupts
            int s = state;
            if (s >= INTERRUPTING)
                handlePossibleCancellationInterrupt(s);
        }
```

```
protected void set(V v) {//如果成功
    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {
        outcome = v;
        UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state
        finishCompletion();
    }
}
```

```
protected void setException(Throwable t) {//如果失败，比如异常
    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {
        outcome = t;//设置outcome=这个异常
        UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state
        finishCompletion();
    }
}
```

```java
public <T> Future<T> submit(Runnable task, T result) {
    if (task == null) throw new NullPointerException();
    RunnableFuture<T> ftask = newTaskFor(task, result);
    execute(ftask);
    return ftask;
}
```

```java
protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {
    return new FutureTask<T>(runnable, value);
}
```

也是放在在Future里面的属性Object outcome里。通过这个 `Future` 对象可以判断任务是否执行成功。

## **如何创建线程池**

《阿里巴巴 Java 开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险

> Executors 返回线程池对象的弊端如下：
>
> - **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。
> - **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。

**方式一：通过构造方法实现** ![ThreadPoolExecutor构造方法](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadPoolExecutor%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95.png) 

| 序号   | 名称              | 类型                       | 含义       |
| ---- | --------------- | ------------------------ | -------- |
| 1    | corePoolSize    | int                      | 核心线程池大小  |
| 2    | maximumPoolSize | int                      | 最大线程池大小  |
| 3    | keepAliveTime   | long                     | 线程最大空闲时间 |
| 4    | unit            | TimeUnit                 | 时间单位     |
| 5    | workQueue       | BlockingQueue<Runnable>  | 线程等待队列   |
| 6    | threadFactory   | ThreadFactory            | 线程创建工厂   |
| 7    | handler         | RejectedExecutionHandler | 拒绝策略     |

**方式二：通过 Executor 框架的工具类 Executors 来实现** 我们可以创建三种类型的 ThreadPoolExecutor：

- **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
- **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
- **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。

## 线程池状态

首先线程池是有状态的，这些状态标识这线程池内部的一些运行情况，线程池的开启到关闭的过程就是线程池状态的一个流转的过程。

线程池共有五种状态：

![thread-pool-executor-status.jpg](https://mmbiz.qpic.cn/mmbiz_jpg/GtXvavW2UlxibQW8iaFzFicbDic8FhXiaqOicXpQsibS8yiabwKf3cemVLJj9VrFAmxictzb1ZJyP6RGxDY2zu0iaKm8NaOw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

| 状态       | 含义                                                         |
| :--------- | :----------------------------------------------------------- |
| RUNNING    | 运行状态，该状态下线程池可以接受新的任务，也可以处理阻塞队列中的任务 执行 shutdown 方法可进入 SHUTDOWN 状态 执行 shutdownNow 方法可进入 STOP 状态 |
| SHUTDOWN   | 待关闭状态，不再接受新的任务，继续处理阻塞队列中的任务 当阻塞队列中的任务为空，并且工作线程数为0时，进入 TIDYING 状态 |
| STOP       | 停止状态，不接收新任务，也不处理阻塞队列中的任务，并且会尝试结束执行中的任务 当工作线程数为0时，进入 TIDYING 状态 |
| TIDYING    | 整理状态，此时任务都已经执行完毕，并且也没有工作线程 执行 terminated 方法后进入 TERMINATED 状态 |
| TERMINATED | 终止状态，此时线程池完全终止了，并完成了所有资源的释放       |

## 重要属性

一个线程池的核心参数有很多，每个参数都有着特殊的作用，各个参数聚合在一起后将完成整个线程池的完整工作。

### 1、线程状态和工作线程数量

首先线程池是有状态的，不同状态下线程池的行为是不一样的，5种状态已经在上面说过了。

另外线程池肯定是需要线程去执行具体的任务的，所以在线程池中就封装了一个内部类 Worker 作为工作线程，每个 Worker 中都维持着一个 Thread。

线程池的重点之一就是控制线程资源合理高效的使用，所以必须控制工作线程的个数，所以需要保存当前线程池中工作线程的个数。

看到这里，你是否觉得需要用两个变量来保存线程池的状态和线程池中工作线程的个数呢？但是在 ThreadPoolExecutor 中只用了一个 AtomicInteger 型的变量就保存了这两个属性的值，那就是 ctl。

![ctl.jpg](https://mmbiz.qpic.cn/mmbiz_jpg/GtXvavW2UlxibQW8iaFzFicbDic8FhXiaqOicXsxR7Nb9iajXu99PQGdPrfGkLoo7F19SibXovNbrQulMSzdibAWkYEicx4Q/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

ctl 的高3位用来表示线程池的状态(runState)，低29位用来表示工作线程的个数(workerCnt)，为什么要用3位来表示线程池的状态呢，原因是线程池一共有5种状态，而2位只能表示出4种情况，所以至少需要3位才能表示得了5种状态。

### 2、核心线程数和最大线程数

现在有了标志工作线程的个数的变量了，那到底该有多少个线程才合适呢？线程多了浪费线程资源，少了又不能发挥线程池的性能。

为了解决这个问题，线程池设计了两个变量来协作，分别是：

- 核心线程数：corePoolSize 用来表示线程池中的核心线程的数量，也可以称为可闲置的线程数量
- 最大线程数：maximumPoolSize 用来表示线程池中最多能够创建的线程数量

现在我们有一个疑问，既然已经有了标识工作线程的个数的变量了，为什么还要有核心线程数、最大线程数呢？

其实你这样想就能够理解了，创建线程是有代价的，不能每次要执行一个任务时就创建一个线程，但是也不能在任务非常多的时候，只有少量的线程在执行，这样任务是来不及处理的，而是应该创建合适的足够多的线程来及时的处理任务。随着任务数量的变化，当任务数明显很小时，原本创建的多余的线程就没有必要再存活着了，因为这时使用少量的线程就能够处理的过来了，所以说真正工作的线程的数量，是随着任务的变化而变化的。

那核心线程数和最大线程数与工作线程个数的关系是什么呢？

![core-maximum-pool-size.jpg](https://mmbiz.qpic.cn/mmbiz_jpg/GtXvavW2UlxibQW8iaFzFicbDic8FhXiaqOicXRWvMBPicHVtePdGQMPTTtVMicQQlnfkM0YSXDprbcpEtUgrXkSaor2oQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

工作线程的个数可能从0到最大线程数之间变化，当执行一段时间之后可能维持在 corePoolSize，但也不是绝对的，取决于核心线程是否允许被超时回收。

### 3、创建线程的工厂

既然是线程池，那自然少不了线程，线程该如何来创建呢？这个任务就交给了线程工厂 ThreadFactory 来完成。

### 4、缓存任务的阻塞队列

上面我们说了核心线程数和最大线程数，并且也介绍了工作线程的个数是在0和最大线程数之间变化的。但是不可能一下子就创建了所有线程，把线程池装满，而是有一个过程，这个过程是这样的：

当线程池接收到一个任务时，如果工作线程数没有达到corePoolSize，那么就会新建一个线程，并绑定该任务，直到工作线程的数量达到 corePoolSize 前都不会重用之前的线程。

当工作线程数达到 corePoolSize 了，这时又接收到新任务时，会将任务存放在一个阻塞队列中等待核心线程去执行。为什么不直接创建更多的线程来执行新任务呢，原因是核心线程中很可能已经有线程执行完自己的任务了，或者有其他线程马上就能处理完当前的任务，并且接下来就能投入到新的任务中去，所以阻塞队列是一种缓冲的机制，给核心线程一个机会让他们充分发挥自己的能力。另外一个值得考虑的原因是，创建线程毕竟是比较昂贵的，不可能一有任务要执行就去创建一个新的线程。

所以我们需要为线程池配备一个阻塞队列，用来临时缓存任务，这些任务将等待工作线程来执行。

![work-queue.jpg](https://mmbiz.qpic.cn/mmbiz_jpg/GtXvavW2UlxibQW8iaFzFicbDic8FhXiaqOicXTedlia8rLXFY0FclQu9jvibLQr082o2zYQAJ4wDDRUITOkgKPrr8ce4Q/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 5、非核心线程存活时间

上面我们说了当工作线程数达到 corePoolSize 时，线程池会将新接收到的任务存放在阻塞队列中，而阻塞队列又两种情况：一种是有界的队列，一种是无界的队列。

**如果是无界队列，那么当核心线程都在忙的时候，所有新提交的任务都会被存放在该无界队列中，这时最大线程数将变得没有意义，因为阻塞队列不会存在被装满的情况。**

如果是有界队列，那么当阻塞队列中装满了等待执行的任务，这时再有新任务提交时，线程池就需要创建新的“临时”线程来处理，相当于增派人手来处理任务。

但是创建的“临时”线程是有存活时间的，不可能让他们一直都存活着，当阻塞队列中的任务被执行完毕，并且又没有那么多新任务被提交时，“临时”线程就需要被回收销毁，在被回收销毁之前等待的这段时间，就是非核心线程的存活时间，也就是 keepAliveTime 属性。

那么什么是“非核心线程”呢？是不是先创建的线程就是核心线程，后创建的就是非核心线程呢？

其实核心线程跟创建的先后没有关系，而是跟工作线程的个数有关，如果当前工作线程的个数大于核心线程数，那么所有的线程都可能是“非核心线程”，都有被回收的可能。

一个线程执行完了一个任务后，会去阻塞队列里面取新的任务，在取到任务之前它就是一个闲置的线程。

**取任务的方法有两种，一种是通过 take() 方法一直阻塞直到取出任务，另一种是通过 poll(keepAliveTime，timeUnit) 方法在一定时间内取出任务或者超时，如果超时这个线程就会被回收，请注意核心线程一般不会被回收。**

那么怎么保证核心线程不会被回收呢？还是跟工作线程的个数有关，每一个线程在取任务的时候，线程池会比较当前的工作线程个数与核心线程数：

- 如果工作线程数小于当前的核心线程数，则使用第一种方法取任务，也就是没有超时回收，这时所有的工作线程都是“核心线程”，他们不会被回收；
- 如果大于核心线程数，则使用第二种方法取任务，一旦超时就回收，所以并没有绝对的核心线程，只要这个线程没有在存活时间内取到任务去执行就会被回收。

所以每个线程想要保住自己“核心线程”的身份，必须充分努力，尽可能快的获取到任务去执行，这样才能逃避被回收的命运。

核心线程一般不会被回收，但是也不是绝对的，如果我们设置了允许核心线程超时被回收的话，那么就没有核心线程这种说法了，所有的线程都会通过 poll(keepAliveTime, timeUnit) 来获取任务，一旦超时获取不到任务，就会被回收，一般很少会这样来使用，除非该线程池需要处理的任务非常少，并且频率也不高，不需要将核心线程一直维持着。

### 6、拒绝策略

虽然我们有了阻塞队列来对任务进行缓存，这从一定程度上为线程池的执行提供了缓冲期，但是如果是有界的阻塞队列，那就存在队列满的情况，也存在工作线程的数据已经达到最大线程数的时候。如果这时候再有新的任务提交时，显然线程池已经心有余而力不足了，因为既没有空余的队列空间来存放该任务，也无法创建新的线程来执行该任务了，所以这时我们就需要有一种拒绝策略，即 handler。

拒绝策略是一个 RejectedExecutionHandler 类型的变量，用户可以自行指定拒绝的策略，如果不指定的话，线程池将使用默认的拒绝策略：抛出异常。

在线程池中还为我们提供了很多其他可以选择的拒绝策略：

- 直接丢弃该任务
- 使用调用者线程执行该任务
- 丢弃任务队列中的最老的一个任务，然后提交该任务

## 工作流程

了解了线程池中所有的重要属性之后，现在我们需要来了解下线程池的工作流程了。

![how-thread-pool-work.jpg](https://mmbiz.qpic.cn/mmbiz_jpg/GtXvavW2UlxibQW8iaFzFicbDic8FhXiaqOicXT8CWic3iaibJs65Ztiaic8aALdyr9Fp1icYKbU3CXoI4oKe3vxIXdZZA5tGw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

上图是一张线程池工作的精简图，实际的过程比这个要复杂的多，不过这些应该能够完全覆盖到线程池的整个工作流程了。

整个过程可以拆分成以下几个部分：

### 1、提交任务

当向线程池提交一个新的任务时，线程池有三种处理情况，分别是：创建一个工作线程来执行该任务、将任务加入阻塞队列、拒绝该任务。

提交任务的过程也可以拆分成以下几个部分：

- 当工作线程数小于核心线程数时，直接创建新的核心工作线程
- 当工作线程数不小于核心线程数时，就需要尝试将任务添加到阻塞队列中去
- 如果能够加入成功，说明队列还没有满，那么需要做以下的二次验证来保证添加进去的任务能够成功被执行
- 验证当前线程池的运行状态，如果是非RUNNING状态，则需要将任务从阻塞队列中移除，然后拒绝该任务
- 验证当前线程池中的工作线程的个数，如果为0，则需要主动添加一个空工作线程来执行刚刚添加到阻塞队列中的任务
- 如果加入失败，则说明队列已经满了，那么这时就需要创建新的“临时”工作线程来执行任务
- 如果创建成功，则直接执行该任务
- 如果创建失败，则说明工作线程数已经等于最大线程数了，则只能拒绝该任务了

整个过程可以用下面这张图来表示：

![execute-runnable.jpg](https://mmbiz.qpic.cn/mmbiz_jpg/GtXvavW2UlxibQW8iaFzFicbDic8FhXiaqOicXvaI4w9N9h3PibJem51dSEFeuibH009pgBrlxEEKn1cMwiaufgfe6iaFkZA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 2、创建工作线程

创建工作线程需要做一系列的判断，需要确保当前线程池可以创建新的线程之后，才能创建。

首先，当线程池的状态是 SHUTDOWN 或者 STOP 时，则不能创建新的线程。

另外，当线程工厂创建线程失败时，也不能创建新的线程。

还有就是当前工作线程的数量与核心线程数、最大线程数进行比较，如果前者大于后者的话，也不允许创建。

除此之外，会尝试通过 CAS 来自增工作线程的个数，如果自增成功了，则会创建新的工作线程，即 Worker 对象。

然后加锁进行二次验证是否能够创建工作线程，最后如果创建成功，则会启动该工作线程。

### 3、启动工作线程

当工作线程创建成功后，也就是 Worker 对象已经创建好了，这时就需要启动该工作线程，让线程开始干活了，Worker 对象中关联着一个 Thread，所以要启动工作线程的话，只要通过 worker.thread.start() 来启动该线程即可。

启动完了之后，就会执行 Worker 对象的 run 方法，因为 Worker 实现了 Runnable 接口，所以本质上 Worker 也是一个线程。

通过线程 start 开启之后就会调用到 Runnable 的 run 方法，在 worker 对象的 run 方法中，调用了 runWorker(this) 方法，也就是把当前对象传递给了 runWorker 方法，让他来执行。

### 4、获取任务并执行

在 runWorker 方法被调用之后，就是执行具体的任务了，首先需要拿到一个可以执行的任务，而 Worker 对象中默认绑定了一个任务，如果该任务不为空的话，那么就是直接执行。

执行完了之后，就会去阻塞队列中获取任务来执行，而获取任务的过程，需要考虑当前工作线程的个数。

- 如果工作线程数大于核心线程数，那么就需要通过 poll 来获取，因为这时需要对闲置的线程进行回收；
- 如果工作线程数小于等于核心线程数，那么就可以通过 take 来获取了，因此这时所有的线程都是核心线程，不需要进行回收，前提是没有设置 allowCoreThreadTimeOut

## `ThreadPoolExecutor`构造函数重要参数分析

**`ThreadPoolExecutor` 3 个最重要的参数：**

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数:

1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. **`unit`** : `keepAliveTime` 参数的时间单位。
3. **`threadFactory`** :executor 创建新线程的时候会用到。
4. **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。

## `ThreadPoolExecutor` 拒绝策略

**`ThreadPoolExecutor` 拒绝策略定义:**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，`ThreadPoolTaskExecutor` 定义一些策略:

- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

举个例子： Spring 通过 `ThreadPoolTaskExecutor` 或者我们直接通过 `ThreadPoolExecutor` 的构造函数创建线程池的时候，当我们不指定 `RejectedExecutionHandler` 饱和策略的话来配置线程池的时候默认使用的是 `ThreadPoolExecutor.AbortPolicy`。在默认情况下，`ThreadPoolExecutor` 将抛出 `RejectedExecutionException` 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 `ThreadPoolExecutor.CallerRunsPolicy`。当最大池被填满时，此策略为我们提供可伸缩队列。（这个直接查看 `ThreadPoolExecutor` 的构造函数源码就可以看出，比较简单的原因，这里就不贴代码了）

## 线程池原理分析

https://www.cnblogs.com/wang-meng/p/12945703.html

https://www.cnblogs.com/wang-meng/p/13023710.html

# CAS

对CAS的理解，CAS是一种无锁算法，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。“比较+更新”整体是一个原子操作。

# ABA

cas的ABA问题，线程1读进x=A，线程2把x的值A改成B又改成A，线程1不知道x的值被修改了。用版本号控制，或者使用juc下原子类**AtomicStampedReference**：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。



# Atomic原子类

## 介绍

Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

所以，所谓原子类说简单点就是具有原子/原子操作特征的类。

并发包 `java.util.concurrent` 的原子类都存放在`java.util.concurrent.atomic`

## JUC 包中的原子类是哪 4 类?

**基本类型**

使用原子的方式更新基本类型

- AtomicInteger：整形原子类
- AtomicLong：长整型原子类
- AtomicBoolean：布尔型原子类

**数组类型**

使用原子的方式更新数组里的某个元素

- AtomicIntegerArray：整形数组原子类
- AtomicLongArray：长整形数组原子类
- AtomicReferenceArray：引用类型数组原子类

**引用类型**

- AtomicReference：引用类型原子类
- AtomicStampedReference：原子更新引用类型里的字段原子类
- AtomicMarkableReference ：原子更新带有标记位的引用类型

**对象的属性修改类型**

- AtomicIntegerFieldUpdater：原子更新整形字段的更新器
- AtomicLongFieldUpdater：原子更新长整形字段的更新器
- AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

## 讲讲 AtomicInteger 的使用

**AtomicInteger 类常用方法**

```java
public final int get() //获取当前的值
public final int getAndSet(int newValue)//获取当前的值，并设置新的值
public final int getAndIncrement()//获取当前的值，并自增
public final int getAndDecrement() //获取当前的值，并自减
public final int getAndAdd(int delta) //获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）
public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
```

**AtomicInteger 类的使用示例**

使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。

```
class AtomicIntegerTest {
        private AtomicInteger count = new AtomicInteger();
      //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。
        public void increment() {
                  count.incrementAndGet();
        }

       public int getCount() {
                return count.get();
        }
}
```

## 能不能给我简单介绍一下 AtomicInteger 类的原理

AtomicInteger 线程安全原理简单分析

AtomicInteger 类的部分源码：

```java
    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }

    private volatile int value;
```

AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

CAS 的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个 volatile 变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。

关于 Atomic 原子类这部分更多内容可以查看我的这篇文章：并发编程面试必备：[JUC 中的 Atomic 原子类总结](https://mp.weixin.qq.com/s/joa-yOiTrYF67bElj8xqvg)

# AQS

## 介绍

AQS 的全称为（AbstractQueuedSynchronizer），这个类在 java.util.concurrent.locks 包下面。

![AQS类](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS%E7%B1%BB.png)

AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。当然，我们自己也能利用 AQS 非常轻松容易地构造出符合我们自己需求的同步器。

## AQS 原理分析

### 原理概览

**AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**

> CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。

看个 AQS(AbstractQueuedSynchronizer)原理图：

![AQS原理图](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS%E5%8E%9F%E7%90%86%E5%9B%BE.png)

**==AQS 使用一个 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。==**

```
private volatile int state;//共享变量，使用volatile修饰保证线程可见性
```

状态信息通过 protected 类型的 getState，setState，compareAndSetState 进行操作

```java
//返回同步状态的当前值
protected final int getState() {
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

### AQS 对资源的共享方式

**AQS 定义两种资源共享方式**

- Exclusive

  （独占）：只有一个线程能执行，如 ReentrantLock。又可分为公平锁和非公平锁：

  - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
  - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的

- **Share**（共享）：多个线程可同时执行，如 Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。

ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某一资源进行读。

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS 已经在顶层实现好了。

### AQS 底层使用了模板方法模式

同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：

1. 使用者继承 AbstractQueuedSynchronizer 并重写指定的方法。（这些重写方法很简单，无非是对于共享资源 state 的获取和释放）
2. 将 AQS 组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。

这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。

**AQS 使用了模板方法模式，自定义同步器时需要重写下面几个 AQS 提供的模板方法：**

```
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

默认情况下，每个方法都抛出 `UnsupportedOperationException`。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS 类中的其他方法都是 final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。

以 ReentrantLock 为例，state 初始化为 0，表示未锁定状态。A 线程 lock()时，会调用 tryAcquire()独占该锁并将 state+1。此后，其他线程再 tryAcquire()时就会失败，直到 A 线程 unlock()到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证 state 是能回到零态的。

再以 CountDownLatch 以例，任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后 countDown()一次，state 会 CAS(Compare and Swap)减 1。等到所有子线程都执行完后(即 state=0)，会 unpark()主调用线程，然后主调用线程就会从 await()函数返回，继续后余动作。

一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现`tryAcquire-tryRelease`、`tryAcquireShared-tryReleaseShared`中的一种即可。但 AQS 也支持自定义同步器同时实现独占和共享两种方式，如`ReentrantReadWriteLock`。

推荐两篇 AQS 原理和相关源码分析的文章：

- http://www.cnblogs.com/waterystone/p/4920797.html
- https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html

### AQS 组件总结

- **Semaphore(信号量)-允许多个线程同时访问：** synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。
- **CountDownLatch （倒计时器）：** CountDownLatch 是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。
- **CyclicBarrier(循环栅栏)：** CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

## 用过 CountDownLatch 么？什么场景下用的？

`CountDownLatch` 的作用就是 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。之前在项目中，有一个使用多线程读取多个文件处理的场景，我用到了 `CountDownLatch` 。具体场景是下面这样的：

我们要读取处理 6 个文件，这 6 个任务都是没有执行顺序依赖的任务，但是我们需要返回给用户的时候将这几个文件的处理的结果进行统计整理。

为此我们定义了一个线程池和 count 为 6 的`CountDownLatch`对象 。使用线程池处理读取任务，每一个线程处理完之后就将 count-1，调用`CountDownLatch`对象的 `await()`方法，直到所有文件读取完之后，才会接着执行后面的逻辑。

伪代码是下面这样的：

```
public class CountDownLatchExample1 {
  // 处理文件的数量
  private static final int threadCount = 6;

  public static void main(String[] args) throws InterruptedException {
    // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）
    ExecutorService threadPool = Executors.newFixedThreadPool(10);
    final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
    for (int i = 0; i < threadCount; i++) {
      final int threadnum = i;
      threadPool.execute(() -> {
        try {
          //处理文件的业务操作
          ......
        } catch (InterruptedException e) {
          e.printStackTrace();
        } finally {
          //表示一个文件已经被完成
          countDownLatch.countDown();
        }

      });
    }
    countDownLatch.await();
    threadPool.shutdown();
    System.out.println("finish");
  }

}
```

**有没有可以改进的地方呢？**

可以使用 `CompletableFuture` 类来改进！Java8 的 `CompletableFuture` 提供了很多对多线程友好的方法，使用它可以很方便地为我们编写多线程程序，什么异步、串行、并行或者等待所有线程执行完任务什么的都非常方便。

```
CompletableFuture<Void> task1 =
  CompletableFuture.supplyAsync(()->{
    //自定义业务操作
  });
......
CompletableFuture<Void> task6 =
  CompletableFuture.supplyAsync(()->{
    //自定义业务操作
  });
......
 CompletableFuture<Void> headerFuture=CompletableFuture.allOf(task1,.....,task6);

  try {
    headerFuture.join();
  } catch (Exception ex) {
    ......
  }
System.out.println("all done. ");
```

上面的代码还可以接续优化，当任务过多的时候，把每一个 task 都列出来不太现实，可以考虑通过循环来添加任务。

```
//文件夹位置
List<String> filePaths = Arrays.asList(...)
// 异步处理所有文件
List<CompletableFuture<String>> fileFutures = filePaths.stream()
        .map(filePath -> doSomeThing(filePath))
        .collect(Collectors.toList());
// 将他们合并起来
CompletableFuture<Void> allFutures = CompletableFuture.allOf(
        fileFutures.toArray(new CompletableFuture[fileFutures.size()])
);
```



# 并发容器

- **ConcurrentHashMap:** 线程安全的 HashMap
- **CopyOnWriteArrayList:** 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector.
- **ConcurrentLinkedQueue:** 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。
- **BlockingQueue:** 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
- **ConcurrentSkipListMap:** 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。


# 拾遗补缺

## sleep() 方法和 wait() 方法区别和共同点?

- 两者最主要的区别在于：**sleep 方法没有释放锁，而 wait 方法释放了锁** 。
- 两者都可以暂停线程的执行。
- Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。
- wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。
- **总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。**

## 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！

new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

## 构造方法可以使用 synchronized 关键字修饰么？

先说结论：**构造方法不能使用 synchronized 关键字修饰。**

构造方法本身就属于线程安全的，不存在同步的构造方法一说。

## synchronized和volatile区别

1) volatile是线程同步的轻易级实现，它的性能比synchronized要好，并且volatile只能修饰变量。而synchronized可以修饰方法及代码块。随着JDK的版本更新，synchronized在执行效率也得到很大的提升，在开发中synchronized的使用率还是较高

2) 多线程访问volatile不会发生阻塞，而synhcronized会出现阻塞

3) volatile能保证数据的可见性，不能保证原子性，而synchronized可以保证原子性，也可以间接保证可见性，因为它会将私有内存和公共内存中的数据做同步。

4) volatile解决的是变量在多个线程之见的可见性，而synchronized是解决多个线程之间访问资源的同步性。

## Synchoronized和cas的引用场景

如果是超高并发，而且锁定代码的执行时间比较长，Synchronized最好。

如果锁的竞争并不激烈，自旋着旋着就拿到锁了，那cas比较好。

Synchronzed里面遇到阻塞wait是不会消耗资源的，但cas是会消耗cpu资源的。
