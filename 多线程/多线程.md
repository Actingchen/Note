# 进程

进程是资源分配的基本单位，也是系统运行程序的基本单位，系统运行一个程序即是一个进程从创建，运行到消亡的过程。

# 线程

线程是cpu调度的基本单位，它是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。多个线程共享他们父进程的**堆**和**方法区**资源,并且每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**

#进程和线程的区别

* 资源：进程是资源分配的基本单位，线程不拥有资源，但线程可以访问他父进程的资源。
* 调度：线程是cpu调度的基本单位，同一进程中的线程切换不会导致进程切换，但从一个进程的线程切换到另一个进程的线程就会导致进程的切换。
* 开销：进程涉及资源的分配和回收，进程的创建和销毁的开销会远大于线程。进程切换涉及进程cpu环境的保存和新调度进程cpu环境的设置，线程只需要保存和设置少量的寄存器内容，所以切换的时候进程的开销也会远大于线程。
* 通信：进程通信需要借助IPC，线程可以直接通过读写进程中的数据进行通信。

#并发和并行

- **并发：** 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)；
- **并行：** 单位时间内，多个任务同时执行。

# 上下文切换

当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。

#Java中sleep()和wait()的区别

1、这两个方法来自不同的类分别是，sleep来自Thread类，和wait来自Object类。

2、最主要是sleep方法没有释放锁，而wait方法释放了锁。

3、使用范围：sleep可以在任何地方使用，而wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用

4、sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常

#为什么我们不能直接调用 run() 方法？

new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。  而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，就不是多线程。

# 线程的生命周期

Thread类的State类定义了java中线程的6中状态：

| 状态         | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| new          | 初始状态，线程被创建，但还没有执行start方法                  |
| runnable     | 运行状态，线程把操作系统中的就绪和运行两种状态笼统地称作运行中 |
| blocked      | 阻塞状态，表示线程阻塞于锁                                   |
| waiting      | 等待状态，表示当前线程需要等待其它线程做出一些通知唤醒或中断 |
| time_waiting | 超时等待状态，该线程等待超过指定时间会自行返回运行状态       |
| terminated   | 终止状态，表示线程已经执行完毕（比如执行完Runnable 的run方法后） |

# 创建线程

1、继承**Thread**和重写run方法

2、实现**Runnable**接口重写run方法

3、实现**Callable**接口重写call方法

# 死锁

## 什么是死锁？

**一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。**

比如，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。

产生死锁必须具备以下四个条件：

1. **互斥条件**：该资源任意一个时刻只由一个线程占用。
2. **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. **不剥夺条件**:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. **循环等待条件**:若干进程之间形成一种头尾相接的循环等待资源关系。

## 如何避免死锁？

避免死锁，只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下：

1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）

2. **破坏请求与保持条件** ：==一次性申请所有的资源==。——>可以增加一个账本管理员，然后只允许账本管理员从文件架上拿账本，也就是说柜员不能直接在文件架上拿账本，必须通过账本管理员才能拿到想要的账本。用这个管理员来保证他们都能够成功申请到所有资源。

3. **破坏不剥夺条件** ：==占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。==

   java.util.concurrent 这个包下面提供的 Lock 是可以轻松解决这个问题的

4. **破坏循环等待条件** ：==靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。==——>最常见的就是B转A的同时，A转账给B，那么先锁B再锁A，但是，另一个线程是先锁A再锁B，然而，如果两个线程同时执行，那么就是出现死锁的情况，线程T1锁了A请求锁B，此时线程T2锁了B请求锁A，都在等着对方释放锁，然而自己都不会释放锁，故死锁。
   最简单的办法，就是无论哪个线程执行的时候，都按照顺序加锁，即按照A和B的id大小来加锁，这样，无论哪个线程执行的时候，都会先加锁A，再加锁B，A被加锁，则等待释放。这样就不会被死锁了。

# ThreadLocal

**含义**

- ThreadLocal的静态内部类是ThreadLocalMap是采用数组entry+开放地址法，每个entry是由key、value组成的，key就是ThreadLocal的弱引用，value就是你存进来的变量副本
- 每一个Thread对象内部都会维护一个ThreadLocalMap，通过一个ThreadLocal对象存值的时候使用的是这个ThreadLocal对象为key，去存到自身线程维护的ThreadLocalMap里面的，实现线程与线程之间的隔离。

**使用场景**

- 线程为作用域并且不同线程具有不同的数据副本的时候，就可以考虑采用ThreadLocal。比如，数据库连接，传值，session管理。

**内存泄漏**

- 当ThreadLocal=null时，GC会把ThreadLocal回收，但是Thread不死，ThreadLocalMap就会一直存在 ，(key没了，value因为是强引用的还在)，这样就造成了内存泄漏，所以在ThreadLocal使用完成后，最好使用完手动调用remove方法。
- ThreadLocal.get()的时候是强引用所以不会发生内存泄漏。

#JMM（Java 内存 模型）

线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程读/写主内存的共享变量的副本。本地内存是JMM的一个抽象概念，它其实是指缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

![img](https://upload-images.jianshu.io/upload_images/4222138-96ca2a788ec29dc2.png?imageMogr2/auto-orient/strip|imageView2/2/w/579/format/webp)

在JVM内部，Java内存模型把内存分成了两部分：线程栈区和堆区

# volatile

**`volatile`**，这就指示 JVM对这个变量的读写，不能使用 CPU 缓存，必须从主。。。。。。。内存中读取或者写入。

## **1、保证可见性**

volatile保证了可见性

当一个变量被volatile修饰时，其中一个线程在其工作内存中对这个变量进行修改时，这个变量会被立即刷新回主内存，而且会使得其他线程的工作内存中这个变量的副本失效，就强制其他线程读取这个变量的时候得去主存读取，这时候读取到的值就是最新值。

> 底层实现主要是通过汇编lock指令，它会锁定这块内存区域的缓存（缓存行锁定）并写回到主内存
>
> lock指令会将当前处理器缓存行的数据立即写回系统内存。

> **MESI缓存一致性协议**:多个cpu从主内存读取同一个数据到各自的高速缓存,当其中某个cpu修改了缓存里的数据,
>
> 该数据会马上同步回主内存,其它cpu通过总线嗅探机制可以感知到数据的变化从而将
>
> 自己缓存里的数据失效。==

* 注意：不能频繁使用volatile，会导致总线风暴。

## **2、保证了有序性/禁止指令重排**

**禁止指令重排的原理**

Volatile实现禁止指令重排优化，从而避免了并发下乱序执行的现象

==主要通过对volatile修饰的变量的读写操作前后加上各种特定的内存屏障来禁止指令重排序来保障有序性的==。

首先了解一个概念，**内存屏障**（Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个：

- 保证特定操作的顺序
- 保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）
  由于编译器和处理器都能执行指令重排的优化，如果在指令键插入一条Memory Barrier则会告诉编译器和CPU,不管什么指令都不能和这条Memory Barrier指令重排序，也就是说，通过插入内存屏障前后的指令执行重排序优化。内存屏障另外一个作用是刷新出各种CPU的缓存数，因此任何cpu上的线程都能读取到这些数据的最新版本
  [![img](https://img2020.cnblogs.com/blog/1164910/202008/1164910-20200816171308095-1818218127.png)](https://img2020.cnblogs.com/blog/1164910/202008/1164910-20200816171308095-1818218127.png)
  也就是在Volatile的写和读的时候，加入屏障，防止出现指令重排

volatile屏蔽掉了JVM中必要的代码优化，所以在效率上比较低，因此只有在必要时才使用此关键字。

## 3、不保证原子性

**原子性**：是要么全部成功，要么全部失败。

简单的说，修改volatile变量分为四步：

1）读取volatile变量到local

2）修改变量值

3）local值写回

4）插入内存屏障，即lock指令，会使其他CPU的缓存无效化，这个使其他线程重新刷新缓存，读取volatile变量，让其它线程立即可见。

虽然内存屏障只会让其他线程每次读取强制从主存读取。但是你还没修改之前别人已经读了，自然没办法刷新。

这也就是为什么，volatile只用来保证变量可见性，但不保证原子性。

eg：线程1线程2对i=1进行i++，我们期望i=2，假如线程1、2同时读到是1，并且都执行i++准备写回主存，此时如果，线程1写回成功，线程2此时虽然可见，但是线程2的读和计算在线程1写回之前已经读过了，所以线程2写回，相当于是覆盖，相当于是这个i++是无效的。所以i<2.

## 使用条件

- 对变量的`写`入操作`不依赖变量的当前值`
- 该变量没有包含在其他变量的不变式中

##适用场景

* 多个线程对一个变量可见并且这个变量更新不频繁（无锁的读写策略：使用锁进行所有变化的操作，使用 volatile 进行只读操作。）

#DCL

```java
public class Singleton {
    private volatile static Singleton instance = null;
    public  static Singleton getInstance() {
        if(null == instance) {
            synchronized (Singleton.class) {
                if(null == instance) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

##**为什么加volatile?**

instance = new Singleton(); 这段代码其实是分为三步执行：

1. 为 instance分配内存空间
2. 初始化instance
3. 将 instance指向分配的内存地址

（不加voliate时）但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 instance不为空，因此返回 instance，但此时 instance 还未被初始化。接着就顺理成章地报错（**对象尚未初始化**）

因此，用volatile关键字修饰instance变量，使得instance在读、写操作前后都会插入内存屏障，避免重排序，保证在多线程环境下也能正常运行。

##**为什么两次判断空？**

1. 第一次校验：由于**单例**模式只需要创建一次实例，如果后面再次调用getInstance方法时，则直接返回之前创建的实例，因此大部分时间不需要执行同步方法里面的代码，大大提高了性能。如果不加第一次校验的话，那跟上面的懒汉模式没什么区别，每次都要去竞争锁。
2. 第二次校验：**多个线程**，比如A和B进入都为空过了第一个条件，然后A拿到锁创建了实例释放，B也创建实例。结果就会导致创建多个实例。所以需要在同步代码里面进行第二次校验，如果实例为空，则进行创建。

#**悲观锁、乐观锁**

**理解**

- 悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。

- 乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。

乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。

**场景**

- 悲观锁适合**写操作多**的场景，因为它总是先加锁，可以保证写操作时数据正确。
- 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。

#**可重入锁、不可重入锁**

**可重入锁**也叫递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），避免了自己锁自己。

**不可重入锁**也叫非递归锁，就会造成死锁（自己锁自己）。因为同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。

# 非公平锁和公平锁

公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。

- 优点：所有的线程都能得到资源，不会饿死在队列中。
- 缺点：吞吐量会下降很多，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销会很大。

非公平锁：多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。

- 优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。
- 缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，导致饿死。

#**CAS**

CAS—— Compare And Swap

CAS算法涉及到三个操作数：

- 需要读写的内存值 V。
- 进行比较的值 （预期值）A。
- 要写入的新值 （要更新的值）B。

当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（**“比较+更新”整体是一个原子操作**），否则不会执行任何操作（报错或者不断重试）。

**CAS存在三大问题**

1. **ABA问题**。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。

2. **自旋时间长的话cpu开销大**。

3. 只能保证**一个共享变量的原子操作**。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

   - Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。

# Synchronized

## **为什么是重量级锁呢？**

因为监视器锁（monitor）是依赖于底层的操作系统的 `Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。

##其原理是什么？

> Synchronized 是由 JVM 实现的一种实现互斥同步的一种方式，在编译前后被编译器生成了 `monitorenter` 和 `monitorexit` 两个字节码指令。

在虚拟机执行到 `monitorenter` 指令时，首先要尝试获取对象的锁，如果这个对象没有锁定就去拿锁，或者当前线程已经拥有了这个对象的锁，把锁的计数器 +1；当执行 `monitorexit` 指令时将锁计数器 -1；当计数器为 0 时，锁就被释放了。如果获取对象失败了，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。

Java 中 Synchronize 通过在对象头设置标记，达到了获取锁和释放锁的目的。

## synchronized 关键字最主要的三种使用方式

**1.修饰实例方法:** `synchronized` 关键字加到实例方法上是给对象实例上锁。

**2.修饰静态方法:**`synchronized` 关键字加到 `static` 静态方法和 `synchronized(class)` 代码块上都是是给 Class 类上锁。

**3.修饰代码块** ：指定加锁对象，对给定对象/类加锁。`synchronized(this|object)` 表示进入同步代码库前要获得**给定对象的锁**。`synchronized(类.class)` 表示进入同步代码前要获得 **当前 class 的锁**

注意：

- 尽量不要使用 `synchronized(String a)` 因为 JVM 中，字符串常量池具有缓存功能！String不能用作同步块的参数是因为String为不可变对象，**任何String对象的改变都将产生一个新的String对象，这也将导致前面加的锁不会被释放**。

- Integer、Boolean、Double、Long不能作为同步块参数的原因是他们是基本包装类型，包装类型有特殊的逻辑，用一句话说就是**Java的自动封箱和解箱操作会导致这些对象在经过运算后不再是原来的对象**。

  用复杂的话说就是：当把基本变量赋值给包装类型的变量（其实编译过后的操作就是调用包装类型的静态方法valueOf）或者调用静态valueOf方法时：

  - Boolean返回的是缓存的对象。
  - 整型（Byte,Short,Integer,Long）会检查该数字是否在1个字节可表示的有符号整数范围内（-128~127），是则返回缓存对象，否则返回新对象。
  - Character会缓存整型值为0~127的字符，同样会检查字符是否落在缓存范围中，是则返回，否则返回新对象。
  - Double和Float的valueOf方法始终返回新对象。

## 锁升级

**锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。**

**Monitor**

Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把Monitor。

四种锁状态对应的的Mark Word内容：

![](..\images\对象头.png)

![](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/7f749fc8.png)

![img](..\images\e8k6xrg5hw.png)



###**无锁**

**无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。**

无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。

###**偏向锁**

**偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。**

偏向锁的获取

当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后**该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程id-------偏向锁**，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。

偏向锁的撤销

偏向锁**使用了一种等到竞争出现才释放锁的机制**，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。**偏向锁的撤销，需要等待全局安全点**（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word，要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。

偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。

###**轻量级锁**

**是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁**，**其他线程会通过自旋的形式尝试获取锁，(场景适合锁占用时间短)不会阻塞，从而提高性能。**缺点是自旋时间长会特别消耗cpu

在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），【虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。

拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。

如果这个更新动作成功了，那么这个线程就拥有了该对象的锁】，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。

如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。

（自旋锁：线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。）

**若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。**

###重量级锁

激烈的竞争进入锁升级状态，变成重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。

重量锁除了具备Mutex(0|1)互斥的功能，它还负责实现了Semaphore(信号量)的功能，也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。

**为什么非公平？**

此时，重量级锁，对象头的mark word里面的标识 会指向对象监视器moniter address  监视器里面有个owner指向线程（表示被哪个线程占据）

当其它线程来访问时，他会先试图直接修改owner，修改失败就会放进锁池即队列里面等待，本质上是非公平锁。owner释放锁owner=null的时候回去锁池唤醒等待线程，等待线程唤醒后就去试图修改owner。

##Synchronized的缺陷

1. 等待中的线程不能被中断
2. 获取锁有没有成功无法获知

#**[ReentrantLock](https://www.cnblogs.com/54chensongxia/p/11970870.html)--可重入锁**

基于AQS实现的

相比`synchronized`，`ReentrantLock`增加了一些高级功能。主要来说主要有三点：

- **等待可中断** :带超时的获取锁尝试 `ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。(如果要求被中断线程不能参与锁的竞争操作，则此时应该使用lockInterruptibly方法，一旦检测到中断请求，立即返回不再参与锁的竞争并且取消锁获取操作)
- **可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock`默认情况是非公平的，可以通过 `ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。非公平锁可能会导致饥饿情况，一直拿不到锁（实际上基本不会发生）
- **可实现选择性通知（锁可以绑定多个条件）**: `synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。

`Condition`是 JDK1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个`Lock`对象中可以创建多个`Condition`实例（即对象监视器），线程对象可以注册在指定的`Condition`中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。如果执行`notifyAll()`方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而`Condition`实例的`signalAll()`方法 只会唤醒注册在该`Condition`实例中的所有等待线程。

**如果你想使用上述功能，那么选择 ReentrantLock 是一个不错的选择。性能已不是选择标准**

lock方法和unlock方法

![img](https://img2020.cnblogs.com/blog/2012006/202011/2012006-20201110155624310-1568890625.png)

##**ReadWriteLock--读写锁**

特点：独占锁（写锁）一次只能被一个线程占有，共享锁（读锁）多个线程可以同时占有。读锁和读锁 可以共存、读锁和写锁 互斥、写锁和写锁 互斥。

# [AQS](https://www.jianshu.com/p/aa4ccf8d9dfb)

## 原理

**AQS 核心思想是，cas的方式请求锁定共享资源，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，新过来请求锁的线程暂时获取不到锁就加入到队列 CLH (先进先出虚拟的双向队列。)中。其中，底层是操作locksupport里的unsafe的park/unpark精准的对线程进行等待和唤醒**。

| 结点状态  | 值   | 描述                                                         |
| --------- | ---- | ------------------------------------------------------------ |
| CANCELLED | 1    | 取消。表示后驱结点被中断或超时，需要移出队列                 |
| SIGNAL    | -1   | 发信号。表示后驱结点被阻塞了（当前结点在入队后、阻塞前，应确保将其prev结点类型改为SIGNAL，以便prev结点取消或释放时将当前结点唤醒。） |
| CONDITION | -2   | Condition专用。表示当前结点在Condition队列中，因为等待某个条件而被阻塞了 |
| PROPAGATE | -3   | 传播。适用于共享模式（比如连续的读操作结点可以依次进入临界区，设为PROPAGATE有助于实现这种迭代操作。） |
| INITIAL   | 0    | 默认。新结点会处于这种状态                                   |

* AQS全称是AbstractQueuedSynchronizer，是一个用来构建锁和同步器的一个框架，AQS提供的是一个线程的排队阻塞的一个功能，这个功能在很多的并发工具都需要使用，所以把这一部分相同的逻辑抽取出来，搞了个AQS。使用AQS去实现同步器的话就不需要再去关心线程的排队和阻塞，只需要继承AQS，然后重写一下钩子方法就能实现出自己的一个同步器。在Java中的ReentrantLock，Semaphore，ReentrantReadWriteLock都是基于AQS实现的。
* AQS内部使用一个==volatile修饰的int变量来表示资源的状态==，变量名叫state。AQS内部维护了一个先进先出的双端队列，用于存储被阻塞的线程的节点，使用head指针和tail指针标识队列的头部和尾部。节点还分是独占的还是共享的，比如ReentrantLock的节点就是独占的，Semaphore的节点是共享的。
* AQS获取资源的核心方法是acquire方法，在acquire里面有一个tryAcquire方法，这是一个钩子，需要子类重写具体的资源的获取逻辑。release方法是释放资源的方法，里面有tryRelease方法，需要子类重写释放资源的具体逻辑。

- AQS线程排队和阻塞的流程

  **AQS使用acquire方法获取资源：**使用子类重写的tryAcquire方法去做资源获取的具体的逻辑，获取资源一般都是用cas去修改state的值。如果没法获取到资源的话就需要对线程进行一个排队和阻塞。

  >step1：首先这个方法调用了用户自己实现的方法`tryAcquire`方法尝试获取资源，如果这个方法返回true，也就是表示获取资源成功，那么整个`acquire`方法就执行结束了，线程继续往下执行；
>
  >step2：如果`tryAcquir`方法返回false，也就表示尝试获取资源失败。这时`acquire`方法会先调用`addWaiter`方法将当前线程封装成Node类并加入一个FIFO的双向队列的尾部。
>
  >step3：再看`acquireQueued`这个**关键方法**。首先要注意的是这个方法中哪个无条件的for循环，这个for循环说明`acquireQueued`方法一直在自旋尝试获取资源。进入for循环后，首先判断了当前节点的前继节点是不是头节点，如果是的话就再次尝试获取资源，获取资源成功的话就直接返回false（表示未被中断过）
>
  >假如还是没有获取资源成功，判断是否需要让当前节点进入`waiting`状态，经过 `shouldParkAfterFailedAcquire`这个方法判断，如果需要让线程进入`waiting`状态的话，就调用LockSupport的park方法让线程进入`waiting`状态。进入`waiting`状态后，这线程等待被`interupt`或者`unpark`（在release操作中会进行这样的操作，可以参见后面的代码）。这个线程被唤醒后继续执行for循环来尝试获取资源。

  **AQS使用release方法去释放资源**：会调用子类实现的tryRelease方法去做资源释放的具体逻辑，然后会判断头节点是不是初始化状态，如果不是的话就表明后续节点可能被阻塞，需要唤醒。==唤醒的时候，如果下一个节点不是cancelled取消节点（表示后驱结点被中断或超时，需要移出队列）的话就唤醒，如果是取消节点的话就需要从队列从后往前扫，唤醒队列里面第一个不是cancelled的节点。==

  为什么是从后往前扫？

  1、在acquireQueue方法里面，如果循环抛异常的话会进到取消节点的方法，取消节点怎么取消，

  之前的addWaiter方法的节点入队并不是原子操作
  
  <img src="https:////upload-images.jianshu.io/upload_images/16782311-50c7a6c2d48b6b0b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom: 25%;" />


   2、标识部分可以看做是 tail 入队的原子操作，但是此时`pred.next = node;`尚未执行，如果这个时候执行了`unparkSuccessor`，就无法从前往后找了

  在产生`CANCELLED`状态节点的时候，先断开的是 next 指针，prev 指针并未断开，因此也是必须要从后往前遍历才能够遍历完

  **AQS 提供了三种操作state的方法**

  - getState()
  - setState(int)
  - compareAndSetState(int, int)

  具体源码如下

  ```
  protected final int getState() {
      return state;
  }
      
  protected final void setState(int newState) {
  state = newState;
  }
      
  protected final boolean compareAndSetState(int expect, int update) {
  // See below for intrinsics setup to support this
  return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
  }
  ```

　　AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。

独占模式下只用实现tryAcquire-tryRelease，而共享模式下只用实现tryAcquireShared-tryReleaseShared

释放掉资源后，唤醒后继。跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。

##AQS 组件总结

- **Semaphore(信号量)**可以指定多个线程同时访问某个资源。

- **CountDownLatch （倒计时器）：** CountDownLatch 是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。

- **CyclicBarrier(循环屏障)**：CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让**一组**线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程（达到拦截数量）到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其**参数表示屏障拦截的线程数量**，每个线程调用 await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

- | 同步器                 | 资源的定义                                                   |
  | ---------------------- | ------------------------------------------------------------ |
  | ReentrantLock          | 资源表示独占锁。State为0表示锁可用；为1表示被占用；为N表示重入的次数 |
  | ReentrantReadWriteLock | 资源表示共享的读锁和独占的写锁。state逻辑上被分成两个16位的unsigned short，分别记录读锁被多少线程使用和写锁被重入的次数。 |
  | CountDownLatch         | 资源表示倒数计数器。State为0表示计数器归零，所有线程都可以访问资源；为N表示计数器未归零，所有线程都需要阻塞。 |
  | Semaphore              | 资源表示信号量或者令牌。State≤0表示没有令牌可用，所有线程都需要阻塞；大于0表示由令牌可用，线程每获取一个令牌，State减1，线程每释放一个令牌，State加1。 |

# [线程池ThreadPoolExecutor](https://www.cnblogs.com/wang-meng/p/12945703.html)

池化思想，重复利用已有线程，降低线程创建销毁的资源消耗，提高响应速度，增加线程的可管理性

* **执行 execute()方法和 submit()方法的区别是什么呢？**

1. **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**
2. **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

- 线程池状态

| 状态       | 说明                                                         |
| ---------- | ------------------------------------------------------------ |
| running    | 运行中状态，能接收新任务                                     |
| shoutdown  | 关闭状态，不接受新任务，但  继续处理已保存在阻塞队列的任务   |
| stop       | 不接受新任务，不处理队列中的任务，会中       断正在处理任务的线程 |
| tidying    | 所有任务终止，workCount（有效线程数）为0                     |
| terminated | 在terminated方法执行后变为该状态                             |

![图3 线程池生命周期](https://p0.meituan.net/travelcube/582d1606d57ff99aa0e5f8fc59c7819329028.png)

==线程池执行流程：==

![执行流程.png](https://img2020.cnblogs.com/other/799093/202005/799093-20200524074816733-172366465.png)

==addWorker方法整体执行流程图如下：==做一些线程池状态的判断，然后新建一个Worker然后调用Worker里面线程的start方法。run方法走的是runWorker方法

![addWorker流程图.png](https://img2020.cnblogs.com/other/799093/202005/799093-20200524074818370-725948824.png)

runWorker会先执行传入的firstTask，执行完成或者说firstTask为空的时候就会去getTask去阻塞队列里面获取任务，在getTask方法里面会根据一些状态去判断是要阻塞当前的线程还是返回null，返回null的话，线程就会退出然后死亡。

* 阻塞队列

| 名称                  | 描述                                                         |
| --------------------- | ------------------------------------------------------------ |
| ArrayBlockingQueue    | 数组实现，先进先出。支持公平锁和非公平锁，需要传入容量大小   |
| LinkedBlockingQueue   | 链表实现，先进先出。默认长度为Integer.MAX_VALUE              |
| PriorityBlockingQueue | 堆实现，支持按优先级排序。无界                               |
| DelayQueue            | 延迟队列，在创建元素时可以指定经过多久才能获取到当前元素     |
| SynchronousQueue      | 一个不存储元素的阻塞队列，每一个put操作必须等待take操作，否则不能添加元素。支持公平锁和非公平锁。这个阻塞队列的一个使用场景是在Executors.newCashedThreadPool()，这个线程池在新任务到来的时候创建新线程，如果有空闲线程的话就会重复使用，否则超过60秒就会被回收 |
| LinkedTransferQueue   | 链表实现，无界，相比于其他阻塞队列增加了transfer和tryTransfer方法 |
| LinkedBlockingDeque   | 链表实现，双向阻塞队列，双端都可以添加和移除元素             |

transfer：

1. 当有消费者线程阻塞等待时，调用transfer方法的生产者线程不会将元素存入队列，而是直接将元素传递给消费者；
2. 如果调用transfer方法的生产者线程发现没有正在等待的消费者线程，则会将元素入队，然后会阻塞等待，直到有一个消费者线程来获取该元素。

tryTransfer：

当生产者线程调用tryTransfer方法时，如果没有消费者等待接收元素，则会立即返回false。该方法和transfer方法的区别就是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法必须等到消费者消费后才返回。

* 拒绝策略

当任务到来时，如果当前运行的线程数达到最大线程数，而且阻塞队列也满了的时候就会触发拒绝策略。

> 策略处理该任务，线程池提供了4种策略：
>1）AbortPolicy：直接抛出异常，默认策略
> 2）CallerRunsPolicy：会调用当前线程池的所在的线程去执行被拒绝的任务，主线程就被阻塞了，别的任务只能在被拒绝的任务执行完之后才会继续被提交到线程池执行。
>3）DiscardOldestPolicy：丢弃阻塞队列中靠最前（最先加入的）的任务，再把这个新任务添加进去
> 4）DiscardPolicy：直接丢弃任务 不抛异常也不执行
>当然线程池是支持自定义拒绝策略的，需要实现RejectedExecutionHandler接口中rejectedExecution()方法即可

* 线程池异常处理问题

  1.submit，底层是Future，线程不会死亡。

  2.UncaughtExceptionHandler，jvm调用，线程死亡。

* 线程池的应用场景

  快速响应用户请求

  比如说要查询一个商品，我们需要对商品的价格，库存，优惠，图片的信息聚合起来再展示给用户，如果串行获取的话就会比较慢，我们可以用线程池，把获取价格，获取优惠，获取库存去包装成一个个任务，然后提交给线程池，让任务并行的执行，缩短响应的时间。这个场景下，因为是要快速嘛，所以线程池的话不应该设置队列去缓冲并发任务，需要调高核心线程数和最大线程数去创造尽可能多的线程去快速完成任务。

  可能会产生的问题

  核心线程数，最大线程数设置过小，如果流量过大的话容易导致频繁地触发拒绝策略。

  阻塞队列容量设置过大，容易导致**任务在队列中堆积**，最大线程数不生效，导致请求超时。

FutureTask

运行我们传入的Callable的call方法，然后将返回值或者异常存储在这个FutureTask的outcome里面，其他的线程能调用这个FutureTask的get方法获取outcome的值。当使用get去获取值的时候，如果这时候call方法还没执行完，还没得到结果，就会新建一个WaitNode节点，然后入队，然后将这个线程挂起。当计算完成得到结果的时候就会去唤醒等待队列里面的线程。

## 线程数和cpu的关系？

一般说来，大家认为线程池的大小经验值应该这样设置：（其中N为CPU的个数）

- 如果是CPU密集型应用，则线程池大小设置为N+磁盘数（一般为1）
- 如果是IO密集型应用，则线程池大小设置为2N+磁盘数（一般为1）

//另外注意一个混合了长事务和短事务的系统，通常是任何连接池都没办法调优的，最好是创建两个连接池，一个服务长事务，一个服务短事务。
