# 集合框架

## 一、List篇

* `ArrayList`
* `LinkedList`
* `Vector`

### ArrayList

因为 ArrayList 是基于数组实现的，支持快速随机访问。数组的默认大小为 10。

#### 1. 扩容

添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 大约是旧容量的 1.5 倍

扩容操作需要调用 `Arrays.copyOf()` 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。

#### 2. 删除元素

需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看到 ArrayList 删除元素的代价是非常高的。

#### 3. 序列化

ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。

保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。

```
transient Object[] elementData; // non-private to simplify nested class access
```

ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。

序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。

#### 4. Fail-Fast

 场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。

modCount 用来记录 ArrayList 结构发生变化的次数。**结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小**，仅仅只是设置元素的值不算结构发生变化。

在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，**如果改变了需要抛出 ConcurrentModificationException。**

####5.缩容

实际上`ArrayList`是不提供自动缩容机制的

但是确实有缩容

```java
public void trimToSize() {
    ``// 修改次数自增
    ``modCount++;
    ``// 判断当前是否需要缩容
    ``if (size < elementData.length) {
      ``// 如果size为0，直接给elementData赋值内置的空数组
      ``// 不为0则创建一个size长度的新数组
      ``elementData = (size == 0)
       ``? EMPTY_ELEMENTDATA
       ``: Arrays.copyOf(elementData, size);
    ``}
  ``}
```

总结

1. `ArrayList`的`remove`只是通过数组部分元素左移、最后一个元素置为`null`同时`size`自减来实现删除操作。实际上并未对`elementData`进行缩容。
2. 可以使用`trimToSize()`方法对`elementData`进行缩容。

### LinkedList

底层数据结构：双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)

```java
//Node节点
private static class Node<E> {
    E item;
    Node<E> next;
    Node<E> prev;

    Node(Node<E> prev, E element, Node<E> next) {
        this.item = element;
        this.next = next;
        this.prev = prev;
    }
}
```

```java
Node<E> node(int index) {
    // assert isElementIndex(index);
    //当查找前半部分的index时候，从头开始遍历
    if (index < (size >> 1)) {
        Node<E> x = first;
        for (int i = 0; i < index; i++)
            x = x.next;
        return x;
    } else {//当查找后半部分的index时候，从尾开始遍历
        Node<E> x = last;
        for (int i = size - 1; i > index; i--)
            x = x.prev;
        return x;
    }
}
```

### Vector

底层数据结构：`Object[]`数组

和 ArrayList 很相似，且内部方法经过了Synchronized修饰。

* **Arraylist 和 Vector 的区别?**
  * Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制；
  * Vector 每次扩容请求其大小的 2 倍（也可以通过构造函数设置增长的容量），而 ArrayList 是 1.5 倍。

##**Arraylist 与 LinkedList 区别?**

1. **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；
2. **底层数据结构：** `Arraylist` 底层使用的是 **Object 数组**；`LinkedList` 底层使用的是 **双向链表** 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）
3. **插入和删除是否受元素位置的影响：** ① **ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。** 比如：执行`add(E e)`方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② **LinkedList 采用链表存储，所以对于add(E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置i插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为o(n))因为需要先移动到指定位置再插入。**
4. **是否支持快速随机访问：** `LinkedList` 不支持高效的随机元素访问，而 `ArrayList` 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。
5. **内存空间占用：** ArrayList 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。

* LinkedList是双向链表结构，在插入时主要消耗时间在遍历操作中定位元素和new节点。另外==在头部尾部LinkedList比较快，越靠近中间越慢。==
* ArrayList是数组结构，在插入时直接通过索引定位到元素，主要消耗在后移操作上。另外，==越往靠近头部插入就越慢。==
* 在相同容量情况下，==尾部插入，两者效率相近；中间插入，ArrayList 速度比 LinkedList 的速度快将近 10 倍；头部插入时，LinkedList比ArrayList效率高。==（因为ArrayList在头部的每一次插入都需要移动 size-1 个元素）

## 二、Map篇

- `HashMap`
- `LinkedHashMap`
- `Hashtable`
- `TreeMap`

### HashMap

它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。

#### 1.确定哈希桶数组索引位置

Hash算法本质上就是三步：**取key的hashCode值、高位运算、取模运算**。

取key的hashCode值：对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。

高位运算：在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。

取模运算：HashMap jdk1.8通过h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。

#### 2.put方法

①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；

②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；

③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；

④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；

⑤.遍历table[i]，判断链表长度是否大于8，大于8的话执行treeifyBin树化操作（这个树化方法里先会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；否则就尾插。

⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

![](..\images\put.png)

```java
1 public V put(K key, V value) {
 2     // 对key的hashCode()做hash
 3     return putVal(hash(key), key, value, false, true);
 4 }
 5 
 6 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
 7                boolean evict) {
 8     Node<K,V>[] tab; Node<K,V> p; int n, i;
 9     // 步骤①：tab为空则创建
10     if ((tab = table) == null || (n = tab.length) == 0)
11         n = (tab = resize()).length;
12     // 步骤②：计算index，并对null做处理 
13     if ((p = tab[i = (n - 1) & hash]) == null) 
14         tab[i] = newNode(hash, key, value, null);
15     else {
16         Node<K,V> e; K k;
17         // 步骤③：节点key存在，直接覆盖value
18         if (p.hash == hash &&
19             ((k = p.key) == key || (key != null && key.equals(k))))
20             e = p;
21         // 步骤④：判断该链为红黑树
22         else if (p instanceof TreeNode)
23             e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
24         // 步骤⑤：该链为链表
25         else {
26             for (int binCount = 0; ; ++binCount) {
27                 if ((e = p.next) == null) {
28                     p.next = newNode(hash, key,value,null);
                        //链表长度大于8转换为红黑树进行处理
29                     if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  
30                         treeifyBin(tab, hash);
31                     break;
32                 }
                    // key已经存在直接覆盖value
33                 if (e.hash == hash &&
34                     ((k = e.key) == key || (key != null && key.equals(k)))) 
35							break;
36                 p = e;
37             }
38         }
39         
40         if (e != null) { // existing mapping for key
41             V oldValue = e.value;
42             if (!onlyIfAbsent || oldValue == null)
43                 e.value = value;
44             afterNodeAccess(e);
45             return oldValue;
46         }
47     }

48     ++modCount;
49     // 步骤⑥：超过最大容量 就扩容
50     if (++size > threshold)
51         resize();
52     afterNodeInsertion(evict);
53     return null;
54 }
```



#### 3.扩容机制

如果容量超过最大极限容量，不会发生扩容，任意它发生碰撞

如果容量>0,就会扩容至原来的两倍

如果容量等于0，就会按照初始容量16创建

重新分配hash值，将桶分配到新的桶里面。

```java
1 final Node<K,V>[] resize() {
 2     Node<K,V>[] oldTab = table;
 3     int oldCap = (oldTab == null) ? 0 : oldTab.length;
 4     int oldThr = threshold;
 5     int newCap, newThr = 0;
 6     if (oldCap > 0) {
 7         // 超过最大值就不再扩充了，就只好随你碰撞去吧
 8         if (oldCap >= MAXIMUM_CAPACITY) {
 9             threshold = Integer.MAX_VALUE;
10             return oldTab;
11         }
12         // 没超过最大值，就扩充为原来的2倍
13         else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
14                  oldCap >= DEFAULT_INITIAL_CAPACITY)
15             newThr = oldThr << 1; // double threshold
16     }
17     else if (oldThr > 0) // initial capacity was placed in threshold
18         newCap = oldThr;
19     else {               // zero initial threshold signifies using defaults
20         newCap = DEFAULT_INITIAL_CAPACITY;
21         newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
22     }
23     // 计算新的resize上限
24     if (newThr == 0) {
25 
26         float ft = (float)newCap * loadFactor;
27         newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
28                   (int)ft : Integer.MAX_VALUE);
29     }
30     threshold = newThr;
31     @SuppressWarnings({"rawtypes"，"unchecked"})
32         Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
33     table = newTab;
34     if (oldTab != null) {
35         // 把每个bucket都移动到新的buckets中
36         for (int j = 0; j < oldCap; ++j) {
37             Node<K,V> e;
38             if ((e = oldTab[j]) != null) {
39                 oldTab[j] = null;
40                 if (e.next == null)
41                     newTab[e.hash & (newCap - 1)] = e;
42                 else if (e instanceof TreeNode)
43                     ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
44                 else { // 链表优化重hash的代码块
45                     Node<K,V> loHead = null, loTail = null;
46                     Node<K,V> hiHead = null, hiTail = null;
47                     Node<K,V> next;
48                     do {
49                         next = e.next;
50                         // 原索引
51                         if ((e.hash & oldCap) == 0) {
52                             if (loTail == null)
53                                 loHead = e;
54                             else
55                                 loTail.next = e;
56                             loTail = e;
57                         }
58                         // 原索引+oldCap
59                         else {
60                             if (hiTail == null)
61                                 hiHead = e;
62                             else
63                                 hiTail.next = e;
64                             hiTail = e;
65                         }
66                     } while ((e = next) != null);
67                     // 原索引放到bucket里
68                     if (loTail != null) {
69                         loTail.next = null;
70                         newTab[j] = loHead;
71                     }
72                     // 原索引+oldCap放到bucket里
73                     if (hiTail != null) {
74                         hiTail.next = null;
75                         newTab[j + oldCap] = hiHead;
76                     }
77                 }
78             }
79         }
80     }
81     return newTab;
82 }
```

* 多线程下HashMap的死循环问题

  在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。多个线程访问hashmap，key(x)、key(y),如果key触发了resize后next指向key(y),但是key(y)触发resize指向key(x)。造成环形链表，即循环调度死循环使得cpu100%。

### LinkedHashMap

LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。

### Hashtable

Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。

* **HashMap 和 Hashtable 的区别**

1. **线程是否安全：** HashMap 是非线程安全的，HashTable 是线程安全的,因为 HashTable 内部的方法基本都经过`synchronized` 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）；
2. **效率：** 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它；
3. **对 Null key 和 Null value 的支持：** HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；HashTable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。
4. **初始容量大小和每次扩充容量大小的不同 ：** ① 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的`tableSizeFor()`方法保证，下面给出了源代码）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。
5. **底层数据结构：** JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。

### TreeMap

TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。

## 三、Set篇

- `HashSet`
- `LinkedHashSet`
- `TreeSet`

### HashSet

(01) HashSet继承于AbstractSet，并且实现了Set接口。
(02) HashSet的本质是一个"没有重复元素"的集合，它是通过[HashMap](http://www.cnblogs.com/skywang12345/p/3310835.html)实现的。HashSet中含有一个"HashMap类型的成员变量"map，HashSet的操作函数，实际上都是通过map实现的。

常用方法：

```java
boolean         add(E object)
void            clear()
Object          clone()
boolean         contains(Object object)
boolean         isEmpty()
Iterator<E>     iterator()
boolean         remove(Object object)
int             size()
```

```java
  1 package java.util;
  2 
  3 public class HashSet<E>
  4     extends AbstractSet<E>
  5     implements Set<E>, Cloneable, java.io.Serializable
  6 {
  7     static final long serialVersionUID = -5024744406713321676L;
  8 
  9     // HashSet是通过map(HashMap对象)保存内容的
 10     private transient HashMap<E,Object> map;
 11 
 12     // PRESENT是向map中插入key-value对应的value
 13     // 因为HashSet中只需要用到key，而HashMap是key-value键值对；
 14     // 所以，向map中添加键值对时，键值对的值固定是PRESENT
 15     private static final Object PRESENT = new Object();
 16 
 17     // 默认构造函数
 18     public HashSet() {
 19         // 调用HashMap的默认构造函数，创建map
 20         map = new HashMap<E,Object>();
 21     }
 22 
 23     // 带集合的构造函数
 24     public HashSet(Collection<? extends E> c) {
 25         // 创建map。
 26         // 为什么要调用Math.max((int) (c.size()/.75f) + 1, 16)，从 (c.size()/.75f) + 1 和 16 中选择一个比较大的树呢？        
 27         // 首先，说明(c.size()/.75f) + 1
 28         //   因为从HashMap的效率(时间成本和空间成本)考虑，HashMap的加载因子是0.75。
 29         //   当HashMap的“阈值”(阈值=HashMap总的大小*加载因子) < “HashMap实际大小”时，
 30         //   就需要将HashMap的容量翻倍。
 31         //   所以，(c.size()/.75f) + 1 计算出来的正好是总的空间大小。
 32         // 接下来，说明为什么是 16 。
 33         //   HashMap的总的大小，必须是2的指数倍。若创建HashMap时，指定的大小不是2的指数倍；
 34         //   HashMap的构造函数中也会重新计算，找出比“指定大小”大的最小的2的指数倍的数。
 35         //   所以，这里指定为16是从性能考虑。避免重复计算。
 36         map = new HashMap<E,Object>(Math.max((int) (c.size()/.75f) + 1, 16));
 37         // 将集合(c)中的全部元素添加到HashSet中
 38         addAll(c);
 39     }
 40 
 41     // 指定HashSet初始容量和加载因子的构造函数
 42     public HashSet(int initialCapacity, float loadFactor) {
 43         map = new HashMap<E,Object>(initialCapacity, loadFactor);
 44     }
 45 
 46     // 指定HashSet初始容量的构造函数
 47     public HashSet(int initialCapacity) {
 48         map = new HashMap<E,Object>(initialCapacity);
 49     }
 50 
 51     HashSet(int initialCapacity, float loadFactor, boolean dummy) {
 52         map = new LinkedHashMap<E,Object>(initialCapacity, loadFactor);
 53     }
 54 
 55     // 返回HashSet的迭代器
 56     public Iterator<E> iterator() {
 57         // 实际上返回的是HashMap的“key集合的迭代器”
 58         return map.keySet().iterator();
 59     }
 60 
 61     public int size() {
 62         return map.size();
 63     }
 64 
 65     public boolean isEmpty() {
 66         return map.isEmpty();
 67     }
 68 
 69     public boolean contains(Object o) {
 70         return map.containsKey(o);
 71     }
 72 
 73     // 将元素(e)添加到HashSet中
 74     public boolean add(E e) {
 75         return map.put(e, PRESENT)==null;
 76     }
 77 
 78     // 删除HashSet中的元素(o)
 79     public boolean remove(Object o) {
 80         return map.remove(o)==PRESENT;
 81     }
 82 
 83     public void clear() {
 84         map.clear();
 85     }
 86 
 87     // 克隆一个HashSet，并返回Object对象
 88     public Object clone() {
 89         try {
 90             HashSet<E> newSet = (HashSet<E>) super.clone();
 91             newSet.map = (HashMap<E, Object>) map.clone();
 92             return newSet;
 93         } catch (CloneNotSupportedException e) {
 94             throw new InternalError();
 95         }
 96     }
 97 
 98     // java.io.Serializable的写入函数
 99     // 将HashSet的“总的容量，加载因子，实际容量，所有的元素”都写入到输出流中
100     private void writeObject(java.io.ObjectOutputStream s)
101         throws java.io.IOException {
102         // Write out any hidden serialization magic
103         s.defaultWriteObject();
104 
105         // Write out HashMap capacity and load factor
106         s.writeInt(map.capacity());
107         s.writeFloat(map.loadFactor());
108 
109         // Write out size
110         s.writeInt(map.size());
111 
112         // Write out all elements in the proper order.
113         for (Iterator i=map.keySet().iterator(); i.hasNext(); )
114             s.writeObject(i.next());
115     }
116 
117 
118     // java.io.Serializable的读取函数
119     // 将HashSet的“总的容量，加载因子，实际容量，所有的元素”依次读出
120     private void readObject(java.io.ObjectInputStream s)
121         throws java.io.IOException, ClassNotFoundException {
122         // Read in any hidden serialization magic
123         s.defaultReadObject();
124 
125         // Read in HashMap capacity and load factor and create backing HashMap
126         int capacity = s.readInt();
127         float loadFactor = s.readFloat();
128         map = (((HashSet)this) instanceof LinkedHashSet ?
129                new LinkedHashMap<E,Object>(capacity, loadFactor) :
130                new HashMap<E,Object>(capacity, loadFactor));
131 
132         // Read in size
133         int size = s.readInt();
134 
135         // Read in all elements in the proper order.
136         for (int i=0; i<size; i++) {
137             E e = (E) s.readObject();
138             map.put(e, PRESENT);
139         }
140     }
141 }
```

### LinkedHashSet

`LinkedHashSet` 是 `HashSet` 的子类，并且其内部是通过 `LinkedHashMap` 来实现的。有点类似于我们之前说的 `LinkedHashMap` 其内部是基于 `HashMap` 实现一样，不过还是有一点点区别的

### TreeSet

（有序，唯一）： 红黑树(自平衡的排序二叉树)

## 四、迭代器（Iterator）

　　迭代器是一种设计模式，它是一个对象，它可以遍历并选择序列中的对象，而开发人员不需要了解该序列的底层结构。迭代器通常被称为“轻量级”对象，因为创建它的代价小。

　　Java中的Iterator功能比较简单，并且只能单向移动：

　　(1) 使用方法iterator()要求容器返回一个Iterator。第一次调用Iterator的next()方法时，它返回序列的第一个元素。注意：iterator()方法是java.lang.Iterable接口,被Collection继承。

　　(2) 使用next()获得序列中的下一个元素。

　　(3) 使用hasNext()检查序列中是否还有元素。

　　(4) 使用remove()将迭代器新返回的元素删除。

　　Iterator是Java迭代器最简单的实现，为List设计的ListIterator具有更多的功能，它可以从两个方向遍历List，也可以从List中插入和删除元素。

```java
ArrayList<Integer> l = new ArrayList<Integer>(); 
/*迭代器用于for循环*/
for (Iterator<Integer> iter = l.iterator(); iter.hasNext();) {
  	Integer ntr = iter.next();
	System.out.println(ntr);
 }
 /*迭代器用于while循环*/
Iterator<Integer> iter = l.iterator();
	while(iter.hasNext()){
 	Integer ntr = iter.next();
	System.out.println(ntr);
 }
```

## 五、Java中length、length()、size()的区别

.length()是String的方法
.length方法是数组的方法
size()方法，是List集合的一个方法

## 六、ConcurrentHashMap

我们知道 HashMap 不是线程安全的，在并发场景下如果要保证一种可行的方式是使用 `Collections.synchronizedMap()` 方法来包装我们的 HashMap。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。

所以就有了 HashMap 的线程安全版本—— ConcurrentHashMap 的诞生。在 ConcurrentHashMap 中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过==锁分段技术==只对所操作的段加锁而不影响客户端对其它段的访问。

简单区别：

- 底层数据结构：jdk1.7时底层是分段的数组+链表实现，jdk1.8采用是数组+链表/红黑树。
- 实现线程安全的方式：1）在jdk1.7，ConcurrentHashMap（分段锁）对整个同属组进行了分割分段（Segment），每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段就不会存在锁竞争，提高并发效率。2）在jdk1.8时摈弃了Segment的概念，直接使用node数组+链表+红黑树的数据结构来实现，并发控制使用synchronized和cas来操作。

​     ConcurrentHashmap1.8

https://www.cnblogs.com/lujiango/p/7580558.html

`sizeCtl`含义解释

> **注意：以上这些构造方法中，都涉及到一个变量`sizeCtl`，这个变量是一个非常重要的变量，而且具有非常丰富的含义，它的值不同，对应的含义也不一样，这里我们先对这个变量不同的值的含义做一下说明，后续源码分析过程中，进一步解释**
>
> `sizeCtl`为0，代表数组未初始化， 且数组的初始容量为16
>
> `sizeCtl`为正数，如果数组未初始化，那么其记录的是数组的初始容量，如果数组已经初始化，那么其记录的是数组的扩容阈值
>
> `sizeCtl`为-1，表示数组正在进行初始化
>
> `sizeCtl`小于0，并且不是-1，表示数组正在扩容， -(1+n)，表示此时有n个线程正在共同完成数组的扩容操作,注意之后怎么变为扩容后的新扩容阈值呢？0.75*2n

###put方法

步骤：
1、检查Key或者Value是否为null，
2、得到Kye的hash值
3、如果Node数组是空的，此时才初始化 initTable()，
4、如果找的对应的下标的位置为空，直接new一个Node节点并放入， break；
5、
6、如果对应头结点不为空， 进入同步代码块
判断此头结点的hash值，是否大于零，大于零则说明是链表的头结点在链表中寻找，
如果有相同hash值并且key相同，就直接覆盖，返回旧值 结束
如果没有则就直接放置在链表的尾部
此头节点的Hash值小于零，则说明此节点是红黑二叉树的根节点
调用树的添加元素方法
判断当前数组是否要转变为红黑树

###get

首先获取到Key的hash值，
然后找到对应的数组下标处的元素
如果次元素是我们要找的，直接返回，
如果次元素是null 返回null
如果Key的值< 0 ,说明是红黑树，

###协助扩容

多个线程被分配任务从右到左

ftw节点表示正在扩容，线程一旦插入位置为此节点就会线程协助扩容

###ConcurrentHashMap 1.7和1.8的区别详细

1️⃣整体结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190426100401737.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODg0OTc2,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190426101108134.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODg0OTc2,size_16,color_FFFFFF,t_70)

1.7：Segment + HashEntry + Unsafe
 1.8: 移除 Segment，使锁的粒度更小，Synchronized + CAS + Node + Unsafe

2️⃣put()

1.7：先定位 Segment，再定位桶，put 全程加锁，没有获取锁的线程提前找桶的位置，并最多自旋 64 次获取锁，超过则挂起。
 1.8：由于移除了 Segment，类似 [HashMap](https://www.jianshu.com/p/6c70d265aa7b)，可以直接定位到桶，拿到 first 节点后进行判断：①为空则 [CAS](https://www.jianshu.com/p/98220486426a) 插入；②为 -1 则说明在扩容，则跟着一起扩容；③ else 则加锁 put(类似1.7)

3️⃣get()

基本类似，由于 value 声明为 [volatile](https://www.jianshu.com/p/6c96719bba04)，保证了修改的可见性，因此不需要加锁。

4️⃣resize()

1.7：跟 [HashMap](https://www.jianshu.com/p/6c70d265aa7b) 步骤一样，只不过是搬到单线程中执行，避免了 [HashMap](https://www.jianshu.com/p/6c70d265aa7b) 在 1.7 中扩容时死循环的问题，保证线程安全。
 1.8：支持并发扩容，[HashMap](https://www.jianshu.com/p/6c70d265aa7b) 扩容在1.8中由头插改为尾插(为了避免死循环问题)，ConcurrentHashmap 也是，迁移也是从尾部开始，扩容前在桶的头部放置一个 hash 值为 -1 的节点，这样别的线程访问时就能判断是否该桶已经被其他线程处理过了。

5️⃣size()

1.7：很经典的思路：计算两次，如果不变则返回计算结果，若不一致，则锁住所有的 Segment 求和。
 1.8：用 voliate修饰的baseCount 来存储当前的节点个数，这就设计到 baseCount 并发环境下修改的问题。尝试把要加的值在baseCount的value加，如果拿不到value，就增加value再加。计算总数的话就是value求和

## 注意1：fail—safe

​      采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是**先复制原有集合内容，在拷贝的集合上进行遍历**。

​      原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以**不会触发Concurrent Modification Exception。**

​      缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，**在遍历期间原集合发生的修改迭代器是不知道的。**

​          场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。

## 注意2：正确遍历删除集合元素

（1）for循环遍历

假设想删除集合里面所有的“b”，用普通For循环会失败，这是因为size是变化的，当删除第一个**b**之后，元素会往前移且size从4变成了3，此时下一次遍历会看到的是**c**而不是第二个**b**。因此，没有删除干净。

```java
package blog;

import java.util.ArrayList;
import java.util.List;

public class HowIteReEm {
public static void main(String[] args) {
	List<String> list=new ArrayList<>();
	list.add("a");
	list.add("b");
	list.add("b");
	list.add("c");
	for(int i=0;i<list.size();i++) {
		if(list.get(i)=="b")
		list.remove(i);
	}
	//打印结果
	System.out.println("打印结果");
	for(int i=0;i<list.size();i++) {
		System.out.println(list.get(i));
	}
}
}
1234567891011121314151617181920212223
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201013135832787.png#pic_center)
解决办法：后序开始删除

```java
for(int i=list.size()-1;i>=0;i--) {
		if(list.get(i)=="b")
		list.remove(i);
}
1234
```

（2）for-each遍历

```java
for(String item:list) {
		if("b".equals(item)) {
			list.remove(item);
		}
	}
12345
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201013141220234.png#pic_center)
这涉及到快速失败机制
**什么是快速失败(fail-fast)？**

> 快速失败(fail-fast) 是 Java 集合的一种错误检测机制。在使用迭代器对集合进行遍历的时候，我们在多线程下操作非安全失败(fail-safe)的集合类可能就会触发 fail-fast 机制，导致抛出 ConcurrentModificationException 异常。 另外，在单线程下，如果在遍历过程中对集合对象的内容进行了修改的话也会触发 fail-fast 机制。

如果我们在集合被遍历期间对其进行修改的话，就会改变 modCount 的值，进而导致 modCount != expectedModCount ，进而抛出 ConcurrentModificationException 异常。

```java
final void checkForComodification() {
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
}
1234
```

> 注：通过 Iterator 的方法修改集合的话会同时修改 expectedModCount 的值，所以不会抛出异常。
> 增强 for 循环也是借助迭代器进行遍历。

（3）Iterator遍历

- hasNext()是否有下一个元素
- next()接收下一个元素

```java
Iterator<String> iterator=list.iterator();
	while(iterator.hasNext()) {
		String s=iterator.next();
		if(s.equals("b"))iterator.remove();
}
12345
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201013142839485.png#pic_center)
OK!成功删除！



